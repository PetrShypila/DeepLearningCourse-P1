{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 2\n",
    "------------\n",
    "\n",
    "Previously in `1_notmnist.ipynb`, we created a pickle with formatted datasets for training, development and testing on the [notMNIST dataset](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html).\n",
    "\n",
    "The goal of this assignment is to progressively train deeper and more accurate models using TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in `1_notmnist.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 19456,
     "status": "ok",
     "timestamp": 1449847956073,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "0ddb1607-1fc4-4ddb-de28-6c7ab7fb0c33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = save['train_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    valid_dataset = save['valid_dataset']\n",
    "    valid_labels = save['valid_labels']\n",
    "    test_dataset = save['test_dataset']\n",
    "    test_labels = save['test_labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', train_dataset.shape, train_labels.shape)\n",
    "    print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "    print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 19723,
     "status": "ok",
     "timestamp": 1449847956364,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "2ba0fc75-1487-4ace-a562-cf81cae82793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    # Converts matrix to vector\n",
    "    dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "    # Map 0 to [1.0, 0.0, 0.0 ...], 1 to [0.0, 1.0, 0.0 ...], 2 to [0.0, 0.0, 1.0 ...]\n",
    "    labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nCLVqyQ5vPPH"
   },
   "source": [
    "We're first going to train a multinomial logistic regression using simple gradient descent.\n",
    "\n",
    "TensorFlow works like this:\n",
    "* First you describe the computation that you want to see performed: what the inputs, the variables, and the operations look like. These get created as nodes over a computation graph. This description is all contained within the block below:\n",
    "\n",
    "      with graph.as_default():\n",
    "          ...\n",
    "\n",
    "* Then you can run the operations on this graph as many times as you want by calling `session.run()`, providing it outputs to fetch from the graph that get returned. This runtime operation is all contained in the block below:\n",
    "\n",
    "      with tf.Session(graph=graph) as session:\n",
    "          ...\n",
    "\n",
    "Let's load all the data into TensorFlow and build the computation graph corresponding to our training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Nfv39qvtvOl_"
   },
   "outputs": [],
   "source": [
    "# With gradient descent training, even this much data is prohibitive.\n",
    "# Subset the training data for faster turnaround.\n",
    "train_subset = 10000\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    # Load the training, validation and test data into constants that are\n",
    "    # attached to the graph.\n",
    "    tf_train_dataset = tf.constant(train_dataset[:train_subset, :])\n",
    "    tf_train_labels = tf.constant(train_labels[:train_subset])\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "    # Variables.\n",
    "    # These are the parameters that we are going to be training. The weight\n",
    "    # matrix will be initialized using random values following a (truncated)\n",
    "    # normal distribution. The biases get initialized to zero.\n",
    "    weights = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "    # Training computation.\n",
    "    # We multiply the inputs with the weight matrix, and add biases. We compute\n",
    "    # the softmax and cross-entropy (it's one operation in TensorFlow, because\n",
    "    # it's very common, and it can be optimized). We take the average of this\n",
    "    # cross-entropy across all training examples: that's our loss.\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  \n",
    "    # Optimizer.\n",
    "    # We are going to find the minimum of this loss using gradient descent.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    # These are not part of training, but merely here so that we can report\n",
    "    # accuracy figures as we train.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KQcL4uqISHjP"
   },
   "source": [
    "Let's run this computation and iterate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 9
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 57454,
     "status": "ok",
     "timestamp": 1449847994134,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "z2cjdenH869W",
    "outputId": "4c037ba1-b526-4d8e-e632-91e2a0333267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 16.426373\n",
      "Training accuracy: 13.3%\n",
      "Validation accuracy: 14.9%\n",
      "Loss at step 100: 2.323542\n",
      "Training accuracy: 71.9%\n",
      "Validation accuracy: 69.8%\n",
      "Loss at step 200: 1.866741\n",
      "Training accuracy: 75.0%\n",
      "Validation accuracy: 72.4%\n",
      "Loss at step 300: 1.620099\n",
      "Training accuracy: 76.3%\n",
      "Validation accuracy: 73.3%\n",
      "Loss at step 400: 1.454222\n",
      "Training accuracy: 77.0%\n",
      "Validation accuracy: 74.0%\n",
      "Loss at step 500: 1.331850\n",
      "Training accuracy: 77.8%\n",
      "Validation accuracy: 74.3%\n",
      "Loss at step 600: 1.236560\n",
      "Training accuracy: 78.3%\n",
      "Validation accuracy: 74.5%\n",
      "Loss at step 700: 1.159458\n",
      "Training accuracy: 78.8%\n",
      "Validation accuracy: 74.6%\n",
      "Loss at step 800: 1.095331\n",
      "Training accuracy: 79.3%\n",
      "Validation accuracy: 74.8%\n",
      "Test accuracy: 82.2%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 801\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    # This is a one-time operation which ensures the parameters get initialized as\n",
    "    # we described in the graph: random weights for the matrix, zeros for the\n",
    "    # biases. \n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        # Run the computations. We tell .run() that we want to run the optimizer,\n",
    "        # and get the loss value and the training predictions returned as numpy\n",
    "        # arrays.\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    \n",
    "        if (step % 100 == 0):\n",
    "            print('Loss at step %d: %f' % (step, l))\n",
    "            print('Training accuracy: %.1f%%' % accuracy(predictions, train_labels[:train_subset, :]))\n",
    "            # Calling .eval() on valid_prediction is basically like calling run(), but\n",
    "            # just to get that one numpy array. Note that it recomputes all its graph dependencies.\n",
    "            print('Validation accuracy: %.1f%%' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "            \n",
    "    print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x68f-hxRGm3H"
   },
   "source": [
    "Let's now switch to stochastic gradient descent training instead, which is much faster.\n",
    "\n",
    "The graph will be similar, except that instead of holding all the training data into a constant node, we create a `Placeholder` node which will be fed actual data at every call of `session.run()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "qhPMzWYRGrzM"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "    # Variables.\n",
    "    weights = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "    # Training computation.\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  \n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XmVZESmtG4JH"
   },
   "source": [
    "Let's run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 6
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 66292,
     "status": "ok",
     "timestamp": 1449848003013,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "FoF91pknG_YW",
    "outputId": "d255c80e-954d-4183-ca1c-c7333ce91d0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "OFFSET: 0\n",
      "Minibatch loss at step 0: 15.818896\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 13.6%\n",
      "OFFSET: 128\n",
      "OFFSET: 256\n",
      "OFFSET: 384\n",
      "OFFSET: 512\n",
      "OFFSET: 640\n",
      "OFFSET: 768\n",
      "OFFSET: 896\n",
      "OFFSET: 1024\n",
      "OFFSET: 1152\n",
      "OFFSET: 1280\n",
      "OFFSET: 1408\n",
      "OFFSET: 1536\n",
      "OFFSET: 1664\n",
      "OFFSET: 1792\n",
      "OFFSET: 1920\n",
      "OFFSET: 2048\n",
      "OFFSET: 2176\n",
      "OFFSET: 2304\n",
      "OFFSET: 2432\n",
      "OFFSET: 2560\n",
      "OFFSET: 2688\n",
      "OFFSET: 2816\n",
      "OFFSET: 2944\n",
      "OFFSET: 3072\n",
      "OFFSET: 3200\n",
      "OFFSET: 3328\n",
      "OFFSET: 3456\n",
      "OFFSET: 3584\n",
      "OFFSET: 3712\n",
      "OFFSET: 3840\n",
      "OFFSET: 3968\n",
      "OFFSET: 4096\n",
      "OFFSET: 4224\n",
      "OFFSET: 4352\n",
      "OFFSET: 4480\n",
      "OFFSET: 4608\n",
      "OFFSET: 4736\n",
      "OFFSET: 4864\n",
      "OFFSET: 4992\n",
      "OFFSET: 5120\n",
      "OFFSET: 5248\n",
      "OFFSET: 5376\n",
      "OFFSET: 5504\n",
      "OFFSET: 5632\n",
      "OFFSET: 5760\n",
      "OFFSET: 5888\n",
      "OFFSET: 6016\n",
      "OFFSET: 6144\n",
      "OFFSET: 6272\n",
      "OFFSET: 6400\n",
      "OFFSET: 6528\n",
      "OFFSET: 6656\n",
      "OFFSET: 6784\n",
      "OFFSET: 6912\n",
      "OFFSET: 7040\n",
      "OFFSET: 7168\n",
      "OFFSET: 7296\n",
      "OFFSET: 7424\n",
      "OFFSET: 7552\n",
      "OFFSET: 7680\n",
      "OFFSET: 7808\n",
      "OFFSET: 7936\n",
      "OFFSET: 8064\n",
      "OFFSET: 8192\n",
      "OFFSET: 8320\n",
      "OFFSET: 8448\n",
      "OFFSET: 8576\n",
      "OFFSET: 8704\n",
      "OFFSET: 8832\n",
      "OFFSET: 8960\n",
      "OFFSET: 9088\n",
      "OFFSET: 9216\n",
      "OFFSET: 9344\n",
      "OFFSET: 9472\n",
      "OFFSET: 9600\n",
      "OFFSET: 9728\n",
      "OFFSET: 9856\n",
      "OFFSET: 9984\n",
      "OFFSET: 10112\n",
      "OFFSET: 10240\n",
      "OFFSET: 10368\n",
      "OFFSET: 10496\n",
      "OFFSET: 10624\n",
      "OFFSET: 10752\n",
      "OFFSET: 10880\n",
      "OFFSET: 11008\n",
      "OFFSET: 11136\n",
      "OFFSET: 11264\n",
      "OFFSET: 11392\n",
      "OFFSET: 11520\n",
      "OFFSET: 11648\n",
      "OFFSET: 11776\n",
      "OFFSET: 11904\n",
      "OFFSET: 12032\n",
      "OFFSET: 12160\n",
      "OFFSET: 12288\n",
      "OFFSET: 12416\n",
      "OFFSET: 12544\n",
      "OFFSET: 12672\n",
      "OFFSET: 12800\n",
      "OFFSET: 12928\n",
      "OFFSET: 13056\n",
      "OFFSET: 13184\n",
      "OFFSET: 13312\n",
      "OFFSET: 13440\n",
      "OFFSET: 13568\n",
      "OFFSET: 13696\n",
      "OFFSET: 13824\n",
      "OFFSET: 13952\n",
      "OFFSET: 14080\n",
      "OFFSET: 14208\n",
      "OFFSET: 14336\n",
      "OFFSET: 14464\n",
      "OFFSET: 14592\n",
      "OFFSET: 14720\n",
      "OFFSET: 14848\n",
      "OFFSET: 14976\n",
      "OFFSET: 15104\n",
      "OFFSET: 15232\n",
      "OFFSET: 15360\n",
      "OFFSET: 15488\n",
      "OFFSET: 15616\n",
      "OFFSET: 15744\n",
      "OFFSET: 15872\n",
      "OFFSET: 16000\n",
      "OFFSET: 16128\n",
      "OFFSET: 16256\n",
      "OFFSET: 16384\n",
      "OFFSET: 16512\n",
      "OFFSET: 16640\n",
      "OFFSET: 16768\n",
      "OFFSET: 16896\n",
      "OFFSET: 17024\n",
      "OFFSET: 17152\n",
      "OFFSET: 17280\n",
      "OFFSET: 17408\n",
      "OFFSET: 17536\n",
      "OFFSET: 17664\n",
      "OFFSET: 17792\n",
      "OFFSET: 17920\n",
      "OFFSET: 18048\n",
      "OFFSET: 18176\n",
      "OFFSET: 18304\n",
      "OFFSET: 18432\n",
      "OFFSET: 18560\n",
      "OFFSET: 18688\n",
      "OFFSET: 18816\n",
      "OFFSET: 18944\n",
      "OFFSET: 19072\n",
      "OFFSET: 19200\n",
      "OFFSET: 19328\n",
      "OFFSET: 19456\n",
      "OFFSET: 19584\n",
      "OFFSET: 19712\n",
      "OFFSET: 19840\n",
      "OFFSET: 19968\n",
      "OFFSET: 20096\n",
      "OFFSET: 20224\n",
      "OFFSET: 20352\n",
      "OFFSET: 20480\n",
      "OFFSET: 20608\n",
      "OFFSET: 20736\n",
      "OFFSET: 20864\n",
      "OFFSET: 20992\n",
      "OFFSET: 21120\n",
      "OFFSET: 21248\n",
      "OFFSET: 21376\n",
      "OFFSET: 21504\n",
      "OFFSET: 21632\n",
      "OFFSET: 21760\n",
      "OFFSET: 21888\n",
      "OFFSET: 22016\n",
      "OFFSET: 22144\n",
      "OFFSET: 22272\n",
      "OFFSET: 22400\n",
      "OFFSET: 22528\n",
      "OFFSET: 22656\n",
      "OFFSET: 22784\n",
      "OFFSET: 22912\n",
      "OFFSET: 23040\n",
      "OFFSET: 23168\n",
      "OFFSET: 23296\n",
      "OFFSET: 23424\n",
      "OFFSET: 23552\n",
      "OFFSET: 23680\n",
      "OFFSET: 23808\n",
      "OFFSET: 23936\n",
      "OFFSET: 24064\n",
      "OFFSET: 24192\n",
      "OFFSET: 24320\n",
      "OFFSET: 24448\n",
      "OFFSET: 24576\n",
      "OFFSET: 24704\n",
      "OFFSET: 24832\n",
      "OFFSET: 24960\n",
      "OFFSET: 25088\n",
      "OFFSET: 25216\n",
      "OFFSET: 25344\n",
      "OFFSET: 25472\n",
      "OFFSET: 25600\n",
      "OFFSET: 25728\n",
      "OFFSET: 25856\n",
      "OFFSET: 25984\n",
      "OFFSET: 26112\n",
      "OFFSET: 26240\n",
      "OFFSET: 26368\n",
      "OFFSET: 26496\n",
      "OFFSET: 26624\n",
      "OFFSET: 26752\n",
      "OFFSET: 26880\n",
      "OFFSET: 27008\n",
      "OFFSET: 27136\n",
      "OFFSET: 27264\n",
      "OFFSET: 27392\n",
      "OFFSET: 27520\n",
      "OFFSET: 27648\n",
      "OFFSET: 27776\n",
      "OFFSET: 27904\n",
      "OFFSET: 28032\n",
      "OFFSET: 28160\n",
      "OFFSET: 28288\n",
      "OFFSET: 28416\n",
      "OFFSET: 28544\n",
      "OFFSET: 28672\n",
      "OFFSET: 28800\n",
      "OFFSET: 28928\n",
      "OFFSET: 29056\n",
      "OFFSET: 29184\n",
      "OFFSET: 29312\n",
      "OFFSET: 29440\n",
      "OFFSET: 29568\n",
      "OFFSET: 29696\n",
      "OFFSET: 29824\n",
      "OFFSET: 29952\n",
      "OFFSET: 30080\n",
      "OFFSET: 30208\n",
      "OFFSET: 30336\n",
      "OFFSET: 30464\n",
      "OFFSET: 30592\n",
      "OFFSET: 30720\n",
      "OFFSET: 30848\n",
      "OFFSET: 30976\n",
      "OFFSET: 31104\n",
      "OFFSET: 31232\n",
      "OFFSET: 31360\n",
      "OFFSET: 31488\n",
      "OFFSET: 31616\n",
      "OFFSET: 31744\n",
      "OFFSET: 31872\n",
      "OFFSET: 32000\n",
      "OFFSET: 32128\n",
      "OFFSET: 32256\n",
      "OFFSET: 32384\n",
      "OFFSET: 32512\n",
      "OFFSET: 32640\n",
      "OFFSET: 32768\n",
      "OFFSET: 32896\n",
      "OFFSET: 33024\n",
      "OFFSET: 33152\n",
      "OFFSET: 33280\n",
      "OFFSET: 33408\n",
      "OFFSET: 33536\n",
      "OFFSET: 33664\n",
      "OFFSET: 33792\n",
      "OFFSET: 33920\n",
      "OFFSET: 34048\n",
      "OFFSET: 34176\n",
      "OFFSET: 34304\n",
      "OFFSET: 34432\n",
      "OFFSET: 34560\n",
      "OFFSET: 34688\n",
      "OFFSET: 34816\n",
      "OFFSET: 34944\n",
      "OFFSET: 35072\n",
      "OFFSET: 35200\n",
      "OFFSET: 35328\n",
      "OFFSET: 35456\n",
      "OFFSET: 35584\n",
      "OFFSET: 35712\n",
      "OFFSET: 35840\n",
      "OFFSET: 35968\n",
      "OFFSET: 36096\n",
      "OFFSET: 36224\n",
      "OFFSET: 36352\n",
      "OFFSET: 36480\n",
      "OFFSET: 36608\n",
      "OFFSET: 36736\n",
      "OFFSET: 36864\n",
      "OFFSET: 36992\n",
      "OFFSET: 37120\n",
      "OFFSET: 37248\n",
      "OFFSET: 37376\n",
      "OFFSET: 37504\n",
      "OFFSET: 37632\n",
      "OFFSET: 37760\n",
      "OFFSET: 37888\n",
      "OFFSET: 38016\n",
      "OFFSET: 38144\n",
      "OFFSET: 38272\n",
      "OFFSET: 38400\n",
      "OFFSET: 38528\n",
      "OFFSET: 38656\n",
      "OFFSET: 38784\n",
      "OFFSET: 38912\n",
      "OFFSET: 39040\n",
      "OFFSET: 39168\n",
      "OFFSET: 39296\n",
      "OFFSET: 39424\n",
      "OFFSET: 39552\n",
      "OFFSET: 39680\n",
      "OFFSET: 39808\n",
      "OFFSET: 39936\n",
      "OFFSET: 40064\n",
      "OFFSET: 40192\n",
      "OFFSET: 40320\n",
      "OFFSET: 40448\n",
      "OFFSET: 40576\n",
      "OFFSET: 40704\n",
      "OFFSET: 40832\n",
      "OFFSET: 40960\n",
      "OFFSET: 41088\n",
      "OFFSET: 41216\n",
      "OFFSET: 41344\n",
      "OFFSET: 41472\n",
      "OFFSET: 41600\n",
      "OFFSET: 41728\n",
      "OFFSET: 41856\n",
      "OFFSET: 41984\n",
      "OFFSET: 42112\n",
      "OFFSET: 42240\n",
      "OFFSET: 42368\n",
      "OFFSET: 42496\n",
      "OFFSET: 42624\n",
      "OFFSET: 42752\n",
      "OFFSET: 42880\n",
      "OFFSET: 43008\n",
      "OFFSET: 43136\n",
      "OFFSET: 43264\n",
      "OFFSET: 43392\n",
      "OFFSET: 43520\n",
      "OFFSET: 43648\n",
      "OFFSET: 43776\n",
      "OFFSET: 43904\n",
      "OFFSET: 44032\n",
      "OFFSET: 44160\n",
      "OFFSET: 44288\n",
      "OFFSET: 44416\n",
      "OFFSET: 44544\n",
      "OFFSET: 44672\n",
      "OFFSET: 44800\n",
      "OFFSET: 44928\n",
      "OFFSET: 45056\n",
      "OFFSET: 45184\n",
      "OFFSET: 45312\n",
      "OFFSET: 45440\n",
      "OFFSET: 45568\n",
      "OFFSET: 45696\n",
      "OFFSET: 45824\n",
      "OFFSET: 45952\n",
      "OFFSET: 46080\n",
      "OFFSET: 46208\n",
      "OFFSET: 46336\n",
      "OFFSET: 46464\n",
      "OFFSET: 46592\n",
      "OFFSET: 46720\n",
      "OFFSET: 46848\n",
      "OFFSET: 46976\n",
      "OFFSET: 47104\n",
      "OFFSET: 47232\n",
      "OFFSET: 47360\n",
      "OFFSET: 47488\n",
      "OFFSET: 47616\n",
      "OFFSET: 47744\n",
      "OFFSET: 47872\n",
      "OFFSET: 48000\n",
      "OFFSET: 48128\n",
      "OFFSET: 48256\n",
      "OFFSET: 48384\n",
      "OFFSET: 48512\n",
      "OFFSET: 48640\n",
      "OFFSET: 48768\n",
      "OFFSET: 48896\n",
      "OFFSET: 49024\n",
      "OFFSET: 49152\n",
      "OFFSET: 49280\n",
      "OFFSET: 49408\n",
      "OFFSET: 49536\n",
      "OFFSET: 49664\n",
      "OFFSET: 49792\n",
      "OFFSET: 49920\n",
      "OFFSET: 50048\n",
      "OFFSET: 50176\n",
      "OFFSET: 50304\n",
      "OFFSET: 50432\n",
      "OFFSET: 50560\n",
      "OFFSET: 50688\n",
      "OFFSET: 50816\n",
      "OFFSET: 50944\n",
      "OFFSET: 51072\n",
      "OFFSET: 51200\n",
      "OFFSET: 51328\n",
      "OFFSET: 51456\n",
      "OFFSET: 51584\n",
      "OFFSET: 51712\n",
      "OFFSET: 51840\n",
      "OFFSET: 51968\n",
      "OFFSET: 52096\n",
      "OFFSET: 52224\n",
      "OFFSET: 52352\n",
      "OFFSET: 52480\n",
      "OFFSET: 52608\n",
      "OFFSET: 52736\n",
      "OFFSET: 52864\n",
      "OFFSET: 52992\n",
      "OFFSET: 53120\n",
      "OFFSET: 53248\n",
      "OFFSET: 53376\n",
      "OFFSET: 53504\n",
      "OFFSET: 53632\n",
      "OFFSET: 53760\n",
      "OFFSET: 53888\n",
      "OFFSET: 54016\n",
      "OFFSET: 54144\n",
      "OFFSET: 54272\n",
      "OFFSET: 54400\n",
      "OFFSET: 54528\n",
      "OFFSET: 54656\n",
      "OFFSET: 54784\n",
      "OFFSET: 54912\n",
      "OFFSET: 55040\n",
      "OFFSET: 55168\n",
      "OFFSET: 55296\n",
      "OFFSET: 55424\n",
      "OFFSET: 55552\n",
      "OFFSET: 55680\n",
      "OFFSET: 55808\n",
      "OFFSET: 55936\n",
      "OFFSET: 56064\n",
      "OFFSET: 56192\n",
      "OFFSET: 56320\n",
      "OFFSET: 56448\n",
      "OFFSET: 56576\n",
      "OFFSET: 56704\n",
      "OFFSET: 56832\n",
      "OFFSET: 56960\n",
      "OFFSET: 57088\n",
      "OFFSET: 57216\n",
      "OFFSET: 57344\n",
      "OFFSET: 57472\n",
      "OFFSET: 57600\n",
      "OFFSET: 57728\n",
      "OFFSET: 57856\n",
      "OFFSET: 57984\n",
      "OFFSET: 58112\n",
      "OFFSET: 58240\n",
      "OFFSET: 58368\n",
      "OFFSET: 58496\n",
      "OFFSET: 58624\n",
      "OFFSET: 58752\n",
      "OFFSET: 58880\n",
      "OFFSET: 59008\n",
      "OFFSET: 59136\n",
      "OFFSET: 59264\n",
      "OFFSET: 59392\n",
      "OFFSET: 59520\n",
      "OFFSET: 59648\n",
      "OFFSET: 59776\n",
      "OFFSET: 59904\n",
      "OFFSET: 60032\n",
      "OFFSET: 60160\n",
      "OFFSET: 60288\n",
      "OFFSET: 60416\n",
      "OFFSET: 60544\n",
      "OFFSET: 60672\n",
      "OFFSET: 60800\n",
      "OFFSET: 60928\n",
      "OFFSET: 61056\n",
      "OFFSET: 61184\n",
      "OFFSET: 61312\n",
      "OFFSET: 61440\n",
      "OFFSET: 61568\n",
      "OFFSET: 61696\n",
      "OFFSET: 61824\n",
      "OFFSET: 61952\n",
      "OFFSET: 62080\n",
      "OFFSET: 62208\n",
      "OFFSET: 62336\n",
      "OFFSET: 62464\n",
      "OFFSET: 62592\n",
      "OFFSET: 62720\n",
      "OFFSET: 62848\n",
      "OFFSET: 62976\n",
      "OFFSET: 63104\n",
      "OFFSET: 63232\n",
      "OFFSET: 63360\n",
      "OFFSET: 63488\n",
      "OFFSET: 63616\n",
      "OFFSET: 63744\n",
      "OFFSET: 63872\n",
      "OFFSET: 64000\n",
      "Minibatch loss at step 500: 1.029736\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 75.5%\n",
      "OFFSET: 64128\n",
      "OFFSET: 64256\n",
      "OFFSET: 64384\n",
      "OFFSET: 64512\n",
      "OFFSET: 64640\n",
      "OFFSET: 64768\n",
      "OFFSET: 64896\n",
      "OFFSET: 65024\n",
      "OFFSET: 65152\n",
      "OFFSET: 65280\n",
      "OFFSET: 65408\n",
      "OFFSET: 65536\n",
      "OFFSET: 65664\n",
      "OFFSET: 65792\n",
      "OFFSET: 65920\n",
      "OFFSET: 66048\n",
      "OFFSET: 66176\n",
      "OFFSET: 66304\n",
      "OFFSET: 66432\n",
      "OFFSET: 66560\n",
      "OFFSET: 66688\n",
      "OFFSET: 66816\n",
      "OFFSET: 66944\n",
      "OFFSET: 67072\n",
      "OFFSET: 67200\n",
      "OFFSET: 67328\n",
      "OFFSET: 67456\n",
      "OFFSET: 67584\n",
      "OFFSET: 67712\n",
      "OFFSET: 67840\n",
      "OFFSET: 67968\n",
      "OFFSET: 68096\n",
      "OFFSET: 68224\n",
      "OFFSET: 68352\n",
      "OFFSET: 68480\n",
      "OFFSET: 68608\n",
      "OFFSET: 68736\n",
      "OFFSET: 68864\n",
      "OFFSET: 68992\n",
      "OFFSET: 69120\n",
      "OFFSET: 69248\n",
      "OFFSET: 69376\n",
      "OFFSET: 69504\n",
      "OFFSET: 69632\n",
      "OFFSET: 69760\n",
      "OFFSET: 69888\n",
      "OFFSET: 70016\n",
      "OFFSET: 70144\n",
      "OFFSET: 70272\n",
      "OFFSET: 70400\n",
      "OFFSET: 70528\n",
      "OFFSET: 70656\n",
      "OFFSET: 70784\n",
      "OFFSET: 70912\n",
      "OFFSET: 71040\n",
      "OFFSET: 71168\n",
      "OFFSET: 71296\n",
      "OFFSET: 71424\n",
      "OFFSET: 71552\n",
      "OFFSET: 71680\n",
      "OFFSET: 71808\n",
      "OFFSET: 71936\n",
      "OFFSET: 72064\n",
      "OFFSET: 72192\n",
      "OFFSET: 72320\n",
      "OFFSET: 72448\n",
      "OFFSET: 72576\n",
      "OFFSET: 72704\n",
      "OFFSET: 72832\n",
      "OFFSET: 72960\n",
      "OFFSET: 73088\n",
      "OFFSET: 73216\n",
      "OFFSET: 73344\n",
      "OFFSET: 73472\n",
      "OFFSET: 73600\n",
      "OFFSET: 73728\n",
      "OFFSET: 73856\n",
      "OFFSET: 73984\n",
      "OFFSET: 74112\n",
      "OFFSET: 74240\n",
      "OFFSET: 74368\n",
      "OFFSET: 74496\n",
      "OFFSET: 74624\n",
      "OFFSET: 74752\n",
      "OFFSET: 74880\n",
      "OFFSET: 75008\n",
      "OFFSET: 75136\n",
      "OFFSET: 75264\n",
      "OFFSET: 75392\n",
      "OFFSET: 75520\n",
      "OFFSET: 75648\n",
      "OFFSET: 75776\n",
      "OFFSET: 75904\n",
      "OFFSET: 76032\n",
      "OFFSET: 76160\n",
      "OFFSET: 76288\n",
      "OFFSET: 76416\n",
      "OFFSET: 76544\n",
      "OFFSET: 76672\n",
      "OFFSET: 76800\n",
      "OFFSET: 76928\n",
      "OFFSET: 77056\n",
      "OFFSET: 77184\n",
      "OFFSET: 77312\n",
      "OFFSET: 77440\n",
      "OFFSET: 77568\n",
      "OFFSET: 77696\n",
      "OFFSET: 77824\n",
      "OFFSET: 77952\n",
      "OFFSET: 78080\n",
      "OFFSET: 78208\n",
      "OFFSET: 78336\n",
      "OFFSET: 78464\n",
      "OFFSET: 78592\n",
      "OFFSET: 78720\n",
      "OFFSET: 78848\n",
      "OFFSET: 78976\n",
      "OFFSET: 79104\n",
      "OFFSET: 79232\n",
      "OFFSET: 79360\n",
      "OFFSET: 79488\n",
      "OFFSET: 79616\n",
      "OFFSET: 79744\n",
      "OFFSET: 79872\n",
      "OFFSET: 80000\n",
      "OFFSET: 80128\n",
      "OFFSET: 80256\n",
      "OFFSET: 80384\n",
      "OFFSET: 80512\n",
      "OFFSET: 80640\n",
      "OFFSET: 80768\n",
      "OFFSET: 80896\n",
      "OFFSET: 81024\n",
      "OFFSET: 81152\n",
      "OFFSET: 81280\n",
      "OFFSET: 81408\n",
      "OFFSET: 81536\n",
      "OFFSET: 81664\n",
      "OFFSET: 81792\n",
      "OFFSET: 81920\n",
      "OFFSET: 82048\n",
      "OFFSET: 82176\n",
      "OFFSET: 82304\n",
      "OFFSET: 82432\n",
      "OFFSET: 82560\n",
      "OFFSET: 82688\n",
      "OFFSET: 82816\n",
      "OFFSET: 82944\n",
      "OFFSET: 83072\n",
      "OFFSET: 83200\n",
      "OFFSET: 83328\n",
      "OFFSET: 83456\n",
      "OFFSET: 83584\n",
      "OFFSET: 83712\n",
      "OFFSET: 83840\n",
      "OFFSET: 83968\n",
      "OFFSET: 84096\n",
      "OFFSET: 84224\n",
      "OFFSET: 84352\n",
      "OFFSET: 84480\n",
      "OFFSET: 84608\n",
      "OFFSET: 84736\n",
      "OFFSET: 84864\n",
      "OFFSET: 84992\n",
      "OFFSET: 85120\n",
      "OFFSET: 85248\n",
      "OFFSET: 85376\n",
      "OFFSET: 85504\n",
      "OFFSET: 85632\n",
      "OFFSET: 85760\n",
      "OFFSET: 85888\n",
      "OFFSET: 86016\n",
      "OFFSET: 86144\n",
      "OFFSET: 86272\n",
      "OFFSET: 86400\n",
      "OFFSET: 86528\n",
      "OFFSET: 86656\n",
      "OFFSET: 86784\n",
      "OFFSET: 86912\n",
      "OFFSET: 87040\n",
      "OFFSET: 87168\n",
      "OFFSET: 87296\n",
      "OFFSET: 87424\n",
      "OFFSET: 87552\n",
      "OFFSET: 87680\n",
      "OFFSET: 87808\n",
      "OFFSET: 87936\n",
      "OFFSET: 88064\n",
      "OFFSET: 88192\n",
      "OFFSET: 88320\n",
      "OFFSET: 88448\n",
      "OFFSET: 88576\n",
      "OFFSET: 88704\n",
      "OFFSET: 88832\n",
      "OFFSET: 88960\n",
      "OFFSET: 89088\n",
      "OFFSET: 89216\n",
      "OFFSET: 89344\n",
      "OFFSET: 89472\n",
      "OFFSET: 89600\n",
      "OFFSET: 89728\n",
      "OFFSET: 89856\n",
      "OFFSET: 89984\n",
      "OFFSET: 90112\n",
      "OFFSET: 90240\n",
      "OFFSET: 90368\n",
      "OFFSET: 90496\n",
      "OFFSET: 90624\n",
      "OFFSET: 90752\n",
      "OFFSET: 90880\n",
      "OFFSET: 91008\n",
      "OFFSET: 91136\n",
      "OFFSET: 91264\n",
      "OFFSET: 91392\n",
      "OFFSET: 91520\n",
      "OFFSET: 91648\n",
      "OFFSET: 91776\n",
      "OFFSET: 91904\n",
      "OFFSET: 92032\n",
      "OFFSET: 92160\n",
      "OFFSET: 92288\n",
      "OFFSET: 92416\n",
      "OFFSET: 92544\n",
      "OFFSET: 92672\n",
      "OFFSET: 92800\n",
      "OFFSET: 92928\n",
      "OFFSET: 93056\n",
      "OFFSET: 93184\n",
      "OFFSET: 93312\n",
      "OFFSET: 93440\n",
      "OFFSET: 93568\n",
      "OFFSET: 93696\n",
      "OFFSET: 93824\n",
      "OFFSET: 93952\n",
      "OFFSET: 94080\n",
      "OFFSET: 94208\n",
      "OFFSET: 94336\n",
      "OFFSET: 94464\n",
      "OFFSET: 94592\n",
      "OFFSET: 94720\n",
      "OFFSET: 94848\n",
      "OFFSET: 94976\n",
      "OFFSET: 95104\n",
      "OFFSET: 95232\n",
      "OFFSET: 95360\n",
      "OFFSET: 95488\n",
      "OFFSET: 95616\n",
      "OFFSET: 95744\n",
      "OFFSET: 95872\n",
      "OFFSET: 96000\n",
      "OFFSET: 96128\n",
      "OFFSET: 96256\n",
      "OFFSET: 96384\n",
      "OFFSET: 96512\n",
      "OFFSET: 96640\n",
      "OFFSET: 96768\n",
      "OFFSET: 96896\n",
      "OFFSET: 97024\n",
      "OFFSET: 97152\n",
      "OFFSET: 97280\n",
      "OFFSET: 97408\n",
      "OFFSET: 97536\n",
      "OFFSET: 97664\n",
      "OFFSET: 97792\n",
      "OFFSET: 97920\n",
      "OFFSET: 98048\n",
      "OFFSET: 98176\n",
      "OFFSET: 98304\n",
      "OFFSET: 98432\n",
      "OFFSET: 98560\n",
      "OFFSET: 98688\n",
      "OFFSET: 98816\n",
      "OFFSET: 98944\n",
      "OFFSET: 99072\n",
      "OFFSET: 99200\n",
      "OFFSET: 99328\n",
      "OFFSET: 99456\n",
      "OFFSET: 99584\n",
      "OFFSET: 99712\n",
      "OFFSET: 99840\n",
      "OFFSET: 99968\n",
      "OFFSET: 100096\n",
      "OFFSET: 100224\n",
      "OFFSET: 100352\n",
      "OFFSET: 100480\n",
      "OFFSET: 100608\n",
      "OFFSET: 100736\n",
      "OFFSET: 100864\n",
      "OFFSET: 100992\n",
      "OFFSET: 101120\n",
      "OFFSET: 101248\n",
      "OFFSET: 101376\n",
      "OFFSET: 101504\n",
      "OFFSET: 101632\n",
      "OFFSET: 101760\n",
      "OFFSET: 101888\n",
      "OFFSET: 102016\n",
      "OFFSET: 102144\n",
      "OFFSET: 102272\n",
      "OFFSET: 102400\n",
      "OFFSET: 102528\n",
      "OFFSET: 102656\n",
      "OFFSET: 102784\n",
      "OFFSET: 102912\n",
      "OFFSET: 103040\n",
      "OFFSET: 103168\n",
      "OFFSET: 103296\n",
      "OFFSET: 103424\n",
      "OFFSET: 103552\n",
      "OFFSET: 103680\n",
      "OFFSET: 103808\n",
      "OFFSET: 103936\n",
      "OFFSET: 104064\n",
      "OFFSET: 104192\n",
      "OFFSET: 104320\n",
      "OFFSET: 104448\n",
      "OFFSET: 104576\n",
      "OFFSET: 104704\n",
      "OFFSET: 104832\n",
      "OFFSET: 104960\n",
      "OFFSET: 105088\n",
      "OFFSET: 105216\n",
      "OFFSET: 105344\n",
      "OFFSET: 105472\n",
      "OFFSET: 105600\n",
      "OFFSET: 105728\n",
      "OFFSET: 105856\n",
      "OFFSET: 105984\n",
      "OFFSET: 106112\n",
      "OFFSET: 106240\n",
      "OFFSET: 106368\n",
      "OFFSET: 106496\n",
      "OFFSET: 106624\n",
      "OFFSET: 106752\n",
      "OFFSET: 106880\n",
      "OFFSET: 107008\n",
      "OFFSET: 107136\n",
      "OFFSET: 107264\n",
      "OFFSET: 107392\n",
      "OFFSET: 107520\n",
      "OFFSET: 107648\n",
      "OFFSET: 107776\n",
      "OFFSET: 107904\n",
      "OFFSET: 108032\n",
      "OFFSET: 108160\n",
      "OFFSET: 108288\n",
      "OFFSET: 108416\n",
      "OFFSET: 108544\n",
      "OFFSET: 108672\n",
      "OFFSET: 108800\n",
      "OFFSET: 108928\n",
      "OFFSET: 109056\n",
      "OFFSET: 109184\n",
      "OFFSET: 109312\n",
      "OFFSET: 109440\n",
      "OFFSET: 109568\n",
      "OFFSET: 109696\n",
      "OFFSET: 109824\n",
      "OFFSET: 109952\n",
      "OFFSET: 110080\n",
      "OFFSET: 110208\n",
      "OFFSET: 110336\n",
      "OFFSET: 110464\n",
      "OFFSET: 110592\n",
      "OFFSET: 110720\n",
      "OFFSET: 110848\n",
      "OFFSET: 110976\n",
      "OFFSET: 111104\n",
      "OFFSET: 111232\n",
      "OFFSET: 111360\n",
      "OFFSET: 111488\n",
      "OFFSET: 111616\n",
      "OFFSET: 111744\n",
      "OFFSET: 111872\n",
      "OFFSET: 112000\n",
      "OFFSET: 112128\n",
      "OFFSET: 112256\n",
      "OFFSET: 112384\n",
      "OFFSET: 112512\n",
      "OFFSET: 112640\n",
      "OFFSET: 112768\n",
      "OFFSET: 112896\n",
      "OFFSET: 113024\n",
      "OFFSET: 113152\n",
      "OFFSET: 113280\n",
      "OFFSET: 113408\n",
      "OFFSET: 113536\n",
      "OFFSET: 113664\n",
      "OFFSET: 113792\n",
      "OFFSET: 113920\n",
      "OFFSET: 114048\n",
      "OFFSET: 114176\n",
      "OFFSET: 114304\n",
      "OFFSET: 114432\n",
      "OFFSET: 114560\n",
      "OFFSET: 114688\n",
      "OFFSET: 114816\n",
      "OFFSET: 114944\n",
      "OFFSET: 115072\n",
      "OFFSET: 115200\n",
      "OFFSET: 115328\n",
      "OFFSET: 115456\n",
      "OFFSET: 115584\n",
      "OFFSET: 115712\n",
      "OFFSET: 115840\n",
      "OFFSET: 115968\n",
      "OFFSET: 116096\n",
      "OFFSET: 116224\n",
      "OFFSET: 116352\n",
      "OFFSET: 116480\n",
      "OFFSET: 116608\n",
      "OFFSET: 116736\n",
      "OFFSET: 116864\n",
      "OFFSET: 116992\n",
      "OFFSET: 117120\n",
      "OFFSET: 117248\n",
      "OFFSET: 117376\n",
      "OFFSET: 117504\n",
      "OFFSET: 117632\n",
      "OFFSET: 117760\n",
      "OFFSET: 117888\n",
      "OFFSET: 118016\n",
      "OFFSET: 118144\n",
      "OFFSET: 118272\n",
      "OFFSET: 118400\n",
      "OFFSET: 118528\n",
      "OFFSET: 118656\n",
      "OFFSET: 118784\n",
      "OFFSET: 118912\n",
      "OFFSET: 119040\n",
      "OFFSET: 119168\n",
      "OFFSET: 119296\n",
      "OFFSET: 119424\n",
      "OFFSET: 119552\n",
      "OFFSET: 119680\n",
      "OFFSET: 119808\n",
      "OFFSET: 119936\n",
      "OFFSET: 120064\n",
      "OFFSET: 120192\n",
      "OFFSET: 120320\n",
      "OFFSET: 120448\n",
      "OFFSET: 120576\n",
      "OFFSET: 120704\n",
      "OFFSET: 120832\n",
      "OFFSET: 120960\n",
      "OFFSET: 121088\n",
      "OFFSET: 121216\n",
      "OFFSET: 121344\n",
      "OFFSET: 121472\n",
      "OFFSET: 121600\n",
      "OFFSET: 121728\n",
      "OFFSET: 121856\n",
      "OFFSET: 121984\n",
      "OFFSET: 122112\n",
      "OFFSET: 122240\n",
      "OFFSET: 122368\n",
      "OFFSET: 122496\n",
      "OFFSET: 122624\n",
      "OFFSET: 122752\n",
      "OFFSET: 122880\n",
      "OFFSET: 123008\n",
      "OFFSET: 123136\n",
      "OFFSET: 123264\n",
      "OFFSET: 123392\n",
      "OFFSET: 123520\n",
      "OFFSET: 123648\n",
      "OFFSET: 123776\n",
      "OFFSET: 123904\n",
      "OFFSET: 124032\n",
      "OFFSET: 124160\n",
      "OFFSET: 124288\n",
      "OFFSET: 124416\n",
      "OFFSET: 124544\n",
      "OFFSET: 124672\n",
      "OFFSET: 124800\n",
      "OFFSET: 124928\n",
      "OFFSET: 125056\n",
      "OFFSET: 125184\n",
      "OFFSET: 125312\n",
      "OFFSET: 125440\n",
      "OFFSET: 125568\n",
      "OFFSET: 125696\n",
      "OFFSET: 125824\n",
      "OFFSET: 125952\n",
      "OFFSET: 126080\n",
      "OFFSET: 126208\n",
      "OFFSET: 126336\n",
      "OFFSET: 126464\n",
      "OFFSET: 126592\n",
      "OFFSET: 126720\n",
      "OFFSET: 126848\n",
      "OFFSET: 126976\n",
      "OFFSET: 127104\n",
      "OFFSET: 127232\n",
      "OFFSET: 127360\n",
      "OFFSET: 127488\n",
      "OFFSET: 127616\n",
      "OFFSET: 127744\n",
      "OFFSET: 127872\n",
      "OFFSET: 128000\n",
      "Minibatch loss at step 1000: 1.363517\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 76.4%\n",
      "OFFSET: 128128\n",
      "OFFSET: 128256\n",
      "OFFSET: 128384\n",
      "OFFSET: 128512\n",
      "OFFSET: 128640\n",
      "OFFSET: 128768\n",
      "OFFSET: 128896\n",
      "OFFSET: 129024\n",
      "OFFSET: 129152\n",
      "OFFSET: 129280\n",
      "OFFSET: 129408\n",
      "OFFSET: 129536\n",
      "OFFSET: 129664\n",
      "OFFSET: 129792\n",
      "OFFSET: 129920\n",
      "OFFSET: 130048\n",
      "OFFSET: 130176\n",
      "OFFSET: 130304\n",
      "OFFSET: 130432\n",
      "OFFSET: 130560\n",
      "OFFSET: 130688\n",
      "OFFSET: 130816\n",
      "OFFSET: 130944\n",
      "OFFSET: 131072\n",
      "OFFSET: 131200\n",
      "OFFSET: 131328\n",
      "OFFSET: 131456\n",
      "OFFSET: 131584\n",
      "OFFSET: 131712\n",
      "OFFSET: 131840\n",
      "OFFSET: 131968\n",
      "OFFSET: 132096\n",
      "OFFSET: 132224\n",
      "OFFSET: 132352\n",
      "OFFSET: 132480\n",
      "OFFSET: 132608\n",
      "OFFSET: 132736\n",
      "OFFSET: 132864\n",
      "OFFSET: 132992\n",
      "OFFSET: 133120\n",
      "OFFSET: 133248\n",
      "OFFSET: 133376\n",
      "OFFSET: 133504\n",
      "OFFSET: 133632\n",
      "OFFSET: 133760\n",
      "OFFSET: 133888\n",
      "OFFSET: 134016\n",
      "OFFSET: 134144\n",
      "OFFSET: 134272\n",
      "OFFSET: 134400\n",
      "OFFSET: 134528\n",
      "OFFSET: 134656\n",
      "OFFSET: 134784\n",
      "OFFSET: 134912\n",
      "OFFSET: 135040\n",
      "OFFSET: 135168\n",
      "OFFSET: 135296\n",
      "OFFSET: 135424\n",
      "OFFSET: 135552\n",
      "OFFSET: 135680\n",
      "OFFSET: 135808\n",
      "OFFSET: 135936\n",
      "OFFSET: 136064\n",
      "OFFSET: 136192\n",
      "OFFSET: 136320\n",
      "OFFSET: 136448\n",
      "OFFSET: 136576\n",
      "OFFSET: 136704\n",
      "OFFSET: 136832\n",
      "OFFSET: 136960\n",
      "OFFSET: 137088\n",
      "OFFSET: 137216\n",
      "OFFSET: 137344\n",
      "OFFSET: 137472\n",
      "OFFSET: 137600\n",
      "OFFSET: 137728\n",
      "OFFSET: 137856\n",
      "OFFSET: 137984\n",
      "OFFSET: 138112\n",
      "OFFSET: 138240\n",
      "OFFSET: 138368\n",
      "OFFSET: 138496\n",
      "OFFSET: 138624\n",
      "OFFSET: 138752\n",
      "OFFSET: 138880\n",
      "OFFSET: 139008\n",
      "OFFSET: 139136\n",
      "OFFSET: 139264\n",
      "OFFSET: 139392\n",
      "OFFSET: 139520\n",
      "OFFSET: 139648\n",
      "OFFSET: 139776\n",
      "OFFSET: 139904\n",
      "OFFSET: 140032\n",
      "OFFSET: 140160\n",
      "OFFSET: 140288\n",
      "OFFSET: 140416\n",
      "OFFSET: 140544\n",
      "OFFSET: 140672\n",
      "OFFSET: 140800\n",
      "OFFSET: 140928\n",
      "OFFSET: 141056\n",
      "OFFSET: 141184\n",
      "OFFSET: 141312\n",
      "OFFSET: 141440\n",
      "OFFSET: 141568\n",
      "OFFSET: 141696\n",
      "OFFSET: 141824\n",
      "OFFSET: 141952\n",
      "OFFSET: 142080\n",
      "OFFSET: 142208\n",
      "OFFSET: 142336\n",
      "OFFSET: 142464\n",
      "OFFSET: 142592\n",
      "OFFSET: 142720\n",
      "OFFSET: 142848\n",
      "OFFSET: 142976\n",
      "OFFSET: 143104\n",
      "OFFSET: 143232\n",
      "OFFSET: 143360\n",
      "OFFSET: 143488\n",
      "OFFSET: 143616\n",
      "OFFSET: 143744\n",
      "OFFSET: 143872\n",
      "OFFSET: 144000\n",
      "OFFSET: 144128\n",
      "OFFSET: 144256\n",
      "OFFSET: 144384\n",
      "OFFSET: 144512\n",
      "OFFSET: 144640\n",
      "OFFSET: 144768\n",
      "OFFSET: 144896\n",
      "OFFSET: 145024\n",
      "OFFSET: 145152\n",
      "OFFSET: 145280\n",
      "OFFSET: 145408\n",
      "OFFSET: 145536\n",
      "OFFSET: 145664\n",
      "OFFSET: 145792\n",
      "OFFSET: 145920\n",
      "OFFSET: 146048\n",
      "OFFSET: 146176\n",
      "OFFSET: 146304\n",
      "OFFSET: 146432\n",
      "OFFSET: 146560\n",
      "OFFSET: 146688\n",
      "OFFSET: 146816\n",
      "OFFSET: 146944\n",
      "OFFSET: 147072\n",
      "OFFSET: 147200\n",
      "OFFSET: 147328\n",
      "OFFSET: 147456\n",
      "OFFSET: 147584\n",
      "OFFSET: 147712\n",
      "OFFSET: 147840\n",
      "OFFSET: 147968\n",
      "OFFSET: 148096\n",
      "OFFSET: 148224\n",
      "OFFSET: 148352\n",
      "OFFSET: 148480\n",
      "OFFSET: 148608\n",
      "OFFSET: 148736\n",
      "OFFSET: 148864\n",
      "OFFSET: 148992\n",
      "OFFSET: 149120\n",
      "OFFSET: 149248\n",
      "OFFSET: 149376\n",
      "OFFSET: 149504\n",
      "OFFSET: 149632\n",
      "OFFSET: 149760\n",
      "OFFSET: 149888\n",
      "OFFSET: 150016\n",
      "OFFSET: 150144\n",
      "OFFSET: 150272\n",
      "OFFSET: 150400\n",
      "OFFSET: 150528\n",
      "OFFSET: 150656\n",
      "OFFSET: 150784\n",
      "OFFSET: 150912\n",
      "OFFSET: 151040\n",
      "OFFSET: 151168\n",
      "OFFSET: 151296\n",
      "OFFSET: 151424\n",
      "OFFSET: 151552\n",
      "OFFSET: 151680\n",
      "OFFSET: 151808\n",
      "OFFSET: 151936\n",
      "OFFSET: 152064\n",
      "OFFSET: 152192\n",
      "OFFSET: 152320\n",
      "OFFSET: 152448\n",
      "OFFSET: 152576\n",
      "OFFSET: 152704\n",
      "OFFSET: 152832\n",
      "OFFSET: 152960\n",
      "OFFSET: 153088\n",
      "OFFSET: 153216\n",
      "OFFSET: 153344\n",
      "OFFSET: 153472\n",
      "OFFSET: 153600\n",
      "OFFSET: 153728\n",
      "OFFSET: 153856\n",
      "OFFSET: 153984\n",
      "OFFSET: 154112\n",
      "OFFSET: 154240\n",
      "OFFSET: 154368\n",
      "OFFSET: 154496\n",
      "OFFSET: 154624\n",
      "OFFSET: 154752\n",
      "OFFSET: 154880\n",
      "OFFSET: 155008\n",
      "OFFSET: 155136\n",
      "OFFSET: 155264\n",
      "OFFSET: 155392\n",
      "OFFSET: 155520\n",
      "OFFSET: 155648\n",
      "OFFSET: 155776\n",
      "OFFSET: 155904\n",
      "OFFSET: 156032\n",
      "OFFSET: 156160\n",
      "OFFSET: 156288\n",
      "OFFSET: 156416\n",
      "OFFSET: 156544\n",
      "OFFSET: 156672\n",
      "OFFSET: 156800\n",
      "OFFSET: 156928\n",
      "OFFSET: 157056\n",
      "OFFSET: 157184\n",
      "OFFSET: 157312\n",
      "OFFSET: 157440\n",
      "OFFSET: 157568\n",
      "OFFSET: 157696\n",
      "OFFSET: 157824\n",
      "OFFSET: 157952\n",
      "OFFSET: 158080\n",
      "OFFSET: 158208\n",
      "OFFSET: 158336\n",
      "OFFSET: 158464\n",
      "OFFSET: 158592\n",
      "OFFSET: 158720\n",
      "OFFSET: 158848\n",
      "OFFSET: 158976\n",
      "OFFSET: 159104\n",
      "OFFSET: 159232\n",
      "OFFSET: 159360\n",
      "OFFSET: 159488\n",
      "OFFSET: 159616\n",
      "OFFSET: 159744\n",
      "OFFSET: 159872\n",
      "OFFSET: 160000\n",
      "OFFSET: 160128\n",
      "OFFSET: 160256\n",
      "OFFSET: 160384\n",
      "OFFSET: 160512\n",
      "OFFSET: 160640\n",
      "OFFSET: 160768\n",
      "OFFSET: 160896\n",
      "OFFSET: 161024\n",
      "OFFSET: 161152\n",
      "OFFSET: 161280\n",
      "OFFSET: 161408\n",
      "OFFSET: 161536\n",
      "OFFSET: 161664\n",
      "OFFSET: 161792\n",
      "OFFSET: 161920\n",
      "OFFSET: 162048\n",
      "OFFSET: 162176\n",
      "OFFSET: 162304\n",
      "OFFSET: 162432\n",
      "OFFSET: 162560\n",
      "OFFSET: 162688\n",
      "OFFSET: 162816\n",
      "OFFSET: 162944\n",
      "OFFSET: 163072\n",
      "OFFSET: 163200\n",
      "OFFSET: 163328\n",
      "OFFSET: 163456\n",
      "OFFSET: 163584\n",
      "OFFSET: 163712\n",
      "OFFSET: 163840\n",
      "OFFSET: 163968\n",
      "OFFSET: 164096\n",
      "OFFSET: 164224\n",
      "OFFSET: 164352\n",
      "OFFSET: 164480\n",
      "OFFSET: 164608\n",
      "OFFSET: 164736\n",
      "OFFSET: 164864\n",
      "OFFSET: 164992\n",
      "OFFSET: 165120\n",
      "OFFSET: 165248\n",
      "OFFSET: 165376\n",
      "OFFSET: 165504\n",
      "OFFSET: 165632\n",
      "OFFSET: 165760\n",
      "OFFSET: 165888\n",
      "OFFSET: 166016\n",
      "OFFSET: 166144\n",
      "OFFSET: 166272\n",
      "OFFSET: 166400\n",
      "OFFSET: 166528\n",
      "OFFSET: 166656\n",
      "OFFSET: 166784\n",
      "OFFSET: 166912\n",
      "OFFSET: 167040\n",
      "OFFSET: 167168\n",
      "OFFSET: 167296\n",
      "OFFSET: 167424\n",
      "OFFSET: 167552\n",
      "OFFSET: 167680\n",
      "OFFSET: 167808\n",
      "OFFSET: 167936\n",
      "OFFSET: 168064\n",
      "OFFSET: 168192\n",
      "OFFSET: 168320\n",
      "OFFSET: 168448\n",
      "OFFSET: 168576\n",
      "OFFSET: 168704\n",
      "OFFSET: 168832\n",
      "OFFSET: 168960\n",
      "OFFSET: 169088\n",
      "OFFSET: 169216\n",
      "OFFSET: 169344\n",
      "OFFSET: 169472\n",
      "OFFSET: 169600\n",
      "OFFSET: 169728\n",
      "OFFSET: 169856\n",
      "OFFSET: 169984\n",
      "OFFSET: 170112\n",
      "OFFSET: 170240\n",
      "OFFSET: 170368\n",
      "OFFSET: 170496\n",
      "OFFSET: 170624\n",
      "OFFSET: 170752\n",
      "OFFSET: 170880\n",
      "OFFSET: 171008\n",
      "OFFSET: 171136\n",
      "OFFSET: 171264\n",
      "OFFSET: 171392\n",
      "OFFSET: 171520\n",
      "OFFSET: 171648\n",
      "OFFSET: 171776\n",
      "OFFSET: 171904\n",
      "OFFSET: 172032\n",
      "OFFSET: 172160\n",
      "OFFSET: 172288\n",
      "OFFSET: 172416\n",
      "OFFSET: 172544\n",
      "OFFSET: 172672\n",
      "OFFSET: 172800\n",
      "OFFSET: 172928\n",
      "OFFSET: 173056\n",
      "OFFSET: 173184\n",
      "OFFSET: 173312\n",
      "OFFSET: 173440\n",
      "OFFSET: 173568\n",
      "OFFSET: 173696\n",
      "OFFSET: 173824\n",
      "OFFSET: 173952\n",
      "OFFSET: 174080\n",
      "OFFSET: 174208\n",
      "OFFSET: 174336\n",
      "OFFSET: 174464\n",
      "OFFSET: 174592\n",
      "OFFSET: 174720\n",
      "OFFSET: 174848\n",
      "OFFSET: 174976\n",
      "OFFSET: 175104\n",
      "OFFSET: 175232\n",
      "OFFSET: 175360\n",
      "OFFSET: 175488\n",
      "OFFSET: 175616\n",
      "OFFSET: 175744\n",
      "OFFSET: 175872\n",
      "OFFSET: 176000\n",
      "OFFSET: 176128\n",
      "OFFSET: 176256\n",
      "OFFSET: 176384\n",
      "OFFSET: 176512\n",
      "OFFSET: 176640\n",
      "OFFSET: 176768\n",
      "OFFSET: 176896\n",
      "OFFSET: 177024\n",
      "OFFSET: 177152\n",
      "OFFSET: 177280\n",
      "OFFSET: 177408\n",
      "OFFSET: 177536\n",
      "OFFSET: 177664\n",
      "OFFSET: 177792\n",
      "OFFSET: 177920\n",
      "OFFSET: 178048\n",
      "OFFSET: 178176\n",
      "OFFSET: 178304\n",
      "OFFSET: 178432\n",
      "OFFSET: 178560\n",
      "OFFSET: 178688\n",
      "OFFSET: 178816\n",
      "OFFSET: 178944\n",
      "OFFSET: 179072\n",
      "OFFSET: 179200\n",
      "OFFSET: 179328\n",
      "OFFSET: 179456\n",
      "OFFSET: 179584\n",
      "OFFSET: 179712\n",
      "OFFSET: 179840\n",
      "OFFSET: 179968\n",
      "OFFSET: 180096\n",
      "OFFSET: 180224\n",
      "OFFSET: 180352\n",
      "OFFSET: 180480\n",
      "OFFSET: 180608\n",
      "OFFSET: 180736\n",
      "OFFSET: 180864\n",
      "OFFSET: 180992\n",
      "OFFSET: 181120\n",
      "OFFSET: 181248\n",
      "OFFSET: 181376\n",
      "OFFSET: 181504\n",
      "OFFSET: 181632\n",
      "OFFSET: 181760\n",
      "OFFSET: 181888\n",
      "OFFSET: 182016\n",
      "OFFSET: 182144\n",
      "OFFSET: 182272\n",
      "OFFSET: 182400\n",
      "OFFSET: 182528\n",
      "OFFSET: 182656\n",
      "OFFSET: 182784\n",
      "OFFSET: 182912\n",
      "OFFSET: 183040\n",
      "OFFSET: 183168\n",
      "OFFSET: 183296\n",
      "OFFSET: 183424\n",
      "OFFSET: 183552\n",
      "OFFSET: 183680\n",
      "OFFSET: 183808\n",
      "OFFSET: 183936\n",
      "OFFSET: 184064\n",
      "OFFSET: 184192\n",
      "OFFSET: 184320\n",
      "OFFSET: 184448\n",
      "OFFSET: 184576\n",
      "OFFSET: 184704\n",
      "OFFSET: 184832\n",
      "OFFSET: 184960\n",
      "OFFSET: 185088\n",
      "OFFSET: 185216\n",
      "OFFSET: 185344\n",
      "OFFSET: 185472\n",
      "OFFSET: 185600\n",
      "OFFSET: 185728\n",
      "OFFSET: 185856\n",
      "OFFSET: 185984\n",
      "OFFSET: 186112\n",
      "OFFSET: 186240\n",
      "OFFSET: 186368\n",
      "OFFSET: 186496\n",
      "OFFSET: 186624\n",
      "OFFSET: 186752\n",
      "OFFSET: 186880\n",
      "OFFSET: 187008\n",
      "OFFSET: 187136\n",
      "OFFSET: 187264\n",
      "OFFSET: 187392\n",
      "OFFSET: 187520\n",
      "OFFSET: 187648\n",
      "OFFSET: 187776\n",
      "OFFSET: 187904\n",
      "OFFSET: 188032\n",
      "OFFSET: 188160\n",
      "OFFSET: 188288\n",
      "OFFSET: 188416\n",
      "OFFSET: 188544\n",
      "OFFSET: 188672\n",
      "OFFSET: 188800\n",
      "OFFSET: 188928\n",
      "OFFSET: 189056\n",
      "OFFSET: 189184\n",
      "OFFSET: 189312\n",
      "OFFSET: 189440\n",
      "OFFSET: 189568\n",
      "OFFSET: 189696\n",
      "OFFSET: 189824\n",
      "OFFSET: 189952\n",
      "OFFSET: 190080\n",
      "OFFSET: 190208\n",
      "OFFSET: 190336\n",
      "OFFSET: 190464\n",
      "OFFSET: 190592\n",
      "OFFSET: 190720\n",
      "OFFSET: 190848\n",
      "OFFSET: 190976\n",
      "OFFSET: 191104\n",
      "OFFSET: 191232\n",
      "OFFSET: 191360\n",
      "OFFSET: 191488\n",
      "OFFSET: 191616\n",
      "OFFSET: 191744\n",
      "OFFSET: 191872\n",
      "OFFSET: 192000\n",
      "Minibatch loss at step 1500: 0.704311\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 76.8%\n",
      "OFFSET: 192128\n",
      "OFFSET: 192256\n",
      "OFFSET: 192384\n",
      "OFFSET: 192512\n",
      "OFFSET: 192640\n",
      "OFFSET: 192768\n",
      "OFFSET: 192896\n",
      "OFFSET: 193024\n",
      "OFFSET: 193152\n",
      "OFFSET: 193280\n",
      "OFFSET: 193408\n",
      "OFFSET: 193536\n",
      "OFFSET: 193664\n",
      "OFFSET: 193792\n",
      "OFFSET: 193920\n",
      "OFFSET: 194048\n",
      "OFFSET: 194176\n",
      "OFFSET: 194304\n",
      "OFFSET: 194432\n",
      "OFFSET: 194560\n",
      "OFFSET: 194688\n",
      "OFFSET: 194816\n",
      "OFFSET: 194944\n",
      "OFFSET: 195072\n",
      "OFFSET: 195200\n",
      "OFFSET: 195328\n",
      "OFFSET: 195456\n",
      "OFFSET: 195584\n",
      "OFFSET: 195712\n",
      "OFFSET: 195840\n",
      "OFFSET: 195968\n",
      "OFFSET: 196096\n",
      "OFFSET: 196224\n",
      "OFFSET: 196352\n",
      "OFFSET: 196480\n",
      "OFFSET: 196608\n",
      "OFFSET: 196736\n",
      "OFFSET: 196864\n",
      "OFFSET: 196992\n",
      "OFFSET: 197120\n",
      "OFFSET: 197248\n",
      "OFFSET: 197376\n",
      "OFFSET: 197504\n",
      "OFFSET: 197632\n",
      "OFFSET: 197760\n",
      "OFFSET: 197888\n",
      "OFFSET: 198016\n",
      "OFFSET: 198144\n",
      "OFFSET: 198272\n",
      "OFFSET: 198400\n",
      "OFFSET: 198528\n",
      "OFFSET: 198656\n",
      "OFFSET: 198784\n",
      "OFFSET: 198912\n",
      "OFFSET: 199040\n",
      "OFFSET: 199168\n",
      "OFFSET: 199296\n",
      "OFFSET: 199424\n",
      "OFFSET: 199552\n",
      "OFFSET: 199680\n",
      "OFFSET: 199808\n",
      "OFFSET: 64\n",
      "OFFSET: 192\n",
      "OFFSET: 320\n",
      "OFFSET: 448\n",
      "OFFSET: 576\n",
      "OFFSET: 704\n",
      "OFFSET: 832\n",
      "OFFSET: 960\n",
      "OFFSET: 1088\n",
      "OFFSET: 1216\n",
      "OFFSET: 1344\n",
      "OFFSET: 1472\n",
      "OFFSET: 1600\n",
      "OFFSET: 1728\n",
      "OFFSET: 1856\n",
      "OFFSET: 1984\n",
      "OFFSET: 2112\n",
      "OFFSET: 2240\n",
      "OFFSET: 2368\n",
      "OFFSET: 2496\n",
      "OFFSET: 2624\n",
      "OFFSET: 2752\n",
      "OFFSET: 2880\n",
      "OFFSET: 3008\n",
      "OFFSET: 3136\n",
      "OFFSET: 3264\n",
      "OFFSET: 3392\n",
      "OFFSET: 3520\n",
      "OFFSET: 3648\n",
      "OFFSET: 3776\n",
      "OFFSET: 3904\n",
      "OFFSET: 4032\n",
      "OFFSET: 4160\n",
      "OFFSET: 4288\n",
      "OFFSET: 4416\n",
      "OFFSET: 4544\n",
      "OFFSET: 4672\n",
      "OFFSET: 4800\n",
      "OFFSET: 4928\n",
      "OFFSET: 5056\n",
      "OFFSET: 5184\n",
      "OFFSET: 5312\n",
      "OFFSET: 5440\n",
      "OFFSET: 5568\n",
      "OFFSET: 5696\n",
      "OFFSET: 5824\n",
      "OFFSET: 5952\n",
      "OFFSET: 6080\n",
      "OFFSET: 6208\n",
      "OFFSET: 6336\n",
      "OFFSET: 6464\n",
      "OFFSET: 6592\n",
      "OFFSET: 6720\n",
      "OFFSET: 6848\n",
      "OFFSET: 6976\n",
      "OFFSET: 7104\n",
      "OFFSET: 7232\n",
      "OFFSET: 7360\n",
      "OFFSET: 7488\n",
      "OFFSET: 7616\n",
      "OFFSET: 7744\n",
      "OFFSET: 7872\n",
      "OFFSET: 8000\n",
      "OFFSET: 8128\n",
      "OFFSET: 8256\n",
      "OFFSET: 8384\n",
      "OFFSET: 8512\n",
      "OFFSET: 8640\n",
      "OFFSET: 8768\n",
      "OFFSET: 8896\n",
      "OFFSET: 9024\n",
      "OFFSET: 9152\n",
      "OFFSET: 9280\n",
      "OFFSET: 9408\n",
      "OFFSET: 9536\n",
      "OFFSET: 9664\n",
      "OFFSET: 9792\n",
      "OFFSET: 9920\n",
      "OFFSET: 10048\n",
      "OFFSET: 10176\n",
      "OFFSET: 10304\n",
      "OFFSET: 10432\n",
      "OFFSET: 10560\n",
      "OFFSET: 10688\n",
      "OFFSET: 10816\n",
      "OFFSET: 10944\n",
      "OFFSET: 11072\n",
      "OFFSET: 11200\n",
      "OFFSET: 11328\n",
      "OFFSET: 11456\n",
      "OFFSET: 11584\n",
      "OFFSET: 11712\n",
      "OFFSET: 11840\n",
      "OFFSET: 11968\n",
      "OFFSET: 12096\n",
      "OFFSET: 12224\n",
      "OFFSET: 12352\n",
      "OFFSET: 12480\n",
      "OFFSET: 12608\n",
      "OFFSET: 12736\n",
      "OFFSET: 12864\n",
      "OFFSET: 12992\n",
      "OFFSET: 13120\n",
      "OFFSET: 13248\n",
      "OFFSET: 13376\n",
      "OFFSET: 13504\n",
      "OFFSET: 13632\n",
      "OFFSET: 13760\n",
      "OFFSET: 13888\n",
      "OFFSET: 14016\n",
      "OFFSET: 14144\n",
      "OFFSET: 14272\n",
      "OFFSET: 14400\n",
      "OFFSET: 14528\n",
      "OFFSET: 14656\n",
      "OFFSET: 14784\n",
      "OFFSET: 14912\n",
      "OFFSET: 15040\n",
      "OFFSET: 15168\n",
      "OFFSET: 15296\n",
      "OFFSET: 15424\n",
      "OFFSET: 15552\n",
      "OFFSET: 15680\n",
      "OFFSET: 15808\n",
      "OFFSET: 15936\n",
      "OFFSET: 16064\n",
      "OFFSET: 16192\n",
      "OFFSET: 16320\n",
      "OFFSET: 16448\n",
      "OFFSET: 16576\n",
      "OFFSET: 16704\n",
      "OFFSET: 16832\n",
      "OFFSET: 16960\n",
      "OFFSET: 17088\n",
      "OFFSET: 17216\n",
      "OFFSET: 17344\n",
      "OFFSET: 17472\n",
      "OFFSET: 17600\n",
      "OFFSET: 17728\n",
      "OFFSET: 17856\n",
      "OFFSET: 17984\n",
      "OFFSET: 18112\n",
      "OFFSET: 18240\n",
      "OFFSET: 18368\n",
      "OFFSET: 18496\n",
      "OFFSET: 18624\n",
      "OFFSET: 18752\n",
      "OFFSET: 18880\n",
      "OFFSET: 19008\n",
      "OFFSET: 19136\n",
      "OFFSET: 19264\n",
      "OFFSET: 19392\n",
      "OFFSET: 19520\n",
      "OFFSET: 19648\n",
      "OFFSET: 19776\n",
      "OFFSET: 19904\n",
      "OFFSET: 20032\n",
      "OFFSET: 20160\n",
      "OFFSET: 20288\n",
      "OFFSET: 20416\n",
      "OFFSET: 20544\n",
      "OFFSET: 20672\n",
      "OFFSET: 20800\n",
      "OFFSET: 20928\n",
      "OFFSET: 21056\n",
      "OFFSET: 21184\n",
      "OFFSET: 21312\n",
      "OFFSET: 21440\n",
      "OFFSET: 21568\n",
      "OFFSET: 21696\n",
      "OFFSET: 21824\n",
      "OFFSET: 21952\n",
      "OFFSET: 22080\n",
      "OFFSET: 22208\n",
      "OFFSET: 22336\n",
      "OFFSET: 22464\n",
      "OFFSET: 22592\n",
      "OFFSET: 22720\n",
      "OFFSET: 22848\n",
      "OFFSET: 22976\n",
      "OFFSET: 23104\n",
      "OFFSET: 23232\n",
      "OFFSET: 23360\n",
      "OFFSET: 23488\n",
      "OFFSET: 23616\n",
      "OFFSET: 23744\n",
      "OFFSET: 23872\n",
      "OFFSET: 24000\n",
      "OFFSET: 24128\n",
      "OFFSET: 24256\n",
      "OFFSET: 24384\n",
      "OFFSET: 24512\n",
      "OFFSET: 24640\n",
      "OFFSET: 24768\n",
      "OFFSET: 24896\n",
      "OFFSET: 25024\n",
      "OFFSET: 25152\n",
      "OFFSET: 25280\n",
      "OFFSET: 25408\n",
      "OFFSET: 25536\n",
      "OFFSET: 25664\n",
      "OFFSET: 25792\n",
      "OFFSET: 25920\n",
      "OFFSET: 26048\n",
      "OFFSET: 26176\n",
      "OFFSET: 26304\n",
      "OFFSET: 26432\n",
      "OFFSET: 26560\n",
      "OFFSET: 26688\n",
      "OFFSET: 26816\n",
      "OFFSET: 26944\n",
      "OFFSET: 27072\n",
      "OFFSET: 27200\n",
      "OFFSET: 27328\n",
      "OFFSET: 27456\n",
      "OFFSET: 27584\n",
      "OFFSET: 27712\n",
      "OFFSET: 27840\n",
      "OFFSET: 27968\n",
      "OFFSET: 28096\n",
      "OFFSET: 28224\n",
      "OFFSET: 28352\n",
      "OFFSET: 28480\n",
      "OFFSET: 28608\n",
      "OFFSET: 28736\n",
      "OFFSET: 28864\n",
      "OFFSET: 28992\n",
      "OFFSET: 29120\n",
      "OFFSET: 29248\n",
      "OFFSET: 29376\n",
      "OFFSET: 29504\n",
      "OFFSET: 29632\n",
      "OFFSET: 29760\n",
      "OFFSET: 29888\n",
      "OFFSET: 30016\n",
      "OFFSET: 30144\n",
      "OFFSET: 30272\n",
      "OFFSET: 30400\n",
      "OFFSET: 30528\n",
      "OFFSET: 30656\n",
      "OFFSET: 30784\n",
      "OFFSET: 30912\n",
      "OFFSET: 31040\n",
      "OFFSET: 31168\n",
      "OFFSET: 31296\n",
      "OFFSET: 31424\n",
      "OFFSET: 31552\n",
      "OFFSET: 31680\n",
      "OFFSET: 31808\n",
      "OFFSET: 31936\n",
      "OFFSET: 32064\n",
      "OFFSET: 32192\n",
      "OFFSET: 32320\n",
      "OFFSET: 32448\n",
      "OFFSET: 32576\n",
      "OFFSET: 32704\n",
      "OFFSET: 32832\n",
      "OFFSET: 32960\n",
      "OFFSET: 33088\n",
      "OFFSET: 33216\n",
      "OFFSET: 33344\n",
      "OFFSET: 33472\n",
      "OFFSET: 33600\n",
      "OFFSET: 33728\n",
      "OFFSET: 33856\n",
      "OFFSET: 33984\n",
      "OFFSET: 34112\n",
      "OFFSET: 34240\n",
      "OFFSET: 34368\n",
      "OFFSET: 34496\n",
      "OFFSET: 34624\n",
      "OFFSET: 34752\n",
      "OFFSET: 34880\n",
      "OFFSET: 35008\n",
      "OFFSET: 35136\n",
      "OFFSET: 35264\n",
      "OFFSET: 35392\n",
      "OFFSET: 35520\n",
      "OFFSET: 35648\n",
      "OFFSET: 35776\n",
      "OFFSET: 35904\n",
      "OFFSET: 36032\n",
      "OFFSET: 36160\n",
      "OFFSET: 36288\n",
      "OFFSET: 36416\n",
      "OFFSET: 36544\n",
      "OFFSET: 36672\n",
      "OFFSET: 36800\n",
      "OFFSET: 36928\n",
      "OFFSET: 37056\n",
      "OFFSET: 37184\n",
      "OFFSET: 37312\n",
      "OFFSET: 37440\n",
      "OFFSET: 37568\n",
      "OFFSET: 37696\n",
      "OFFSET: 37824\n",
      "OFFSET: 37952\n",
      "OFFSET: 38080\n",
      "OFFSET: 38208\n",
      "OFFSET: 38336\n",
      "OFFSET: 38464\n",
      "OFFSET: 38592\n",
      "OFFSET: 38720\n",
      "OFFSET: 38848\n",
      "OFFSET: 38976\n",
      "OFFSET: 39104\n",
      "OFFSET: 39232\n",
      "OFFSET: 39360\n",
      "OFFSET: 39488\n",
      "OFFSET: 39616\n",
      "OFFSET: 39744\n",
      "OFFSET: 39872\n",
      "OFFSET: 40000\n",
      "OFFSET: 40128\n",
      "OFFSET: 40256\n",
      "OFFSET: 40384\n",
      "OFFSET: 40512\n",
      "OFFSET: 40640\n",
      "OFFSET: 40768\n",
      "OFFSET: 40896\n",
      "OFFSET: 41024\n",
      "OFFSET: 41152\n",
      "OFFSET: 41280\n",
      "OFFSET: 41408\n",
      "OFFSET: 41536\n",
      "OFFSET: 41664\n",
      "OFFSET: 41792\n",
      "OFFSET: 41920\n",
      "OFFSET: 42048\n",
      "OFFSET: 42176\n",
      "OFFSET: 42304\n",
      "OFFSET: 42432\n",
      "OFFSET: 42560\n",
      "OFFSET: 42688\n",
      "OFFSET: 42816\n",
      "OFFSET: 42944\n",
      "OFFSET: 43072\n",
      "OFFSET: 43200\n",
      "OFFSET: 43328\n",
      "OFFSET: 43456\n",
      "OFFSET: 43584\n",
      "OFFSET: 43712\n",
      "OFFSET: 43840\n",
      "OFFSET: 43968\n",
      "OFFSET: 44096\n",
      "OFFSET: 44224\n",
      "OFFSET: 44352\n",
      "OFFSET: 44480\n",
      "OFFSET: 44608\n",
      "OFFSET: 44736\n",
      "OFFSET: 44864\n",
      "OFFSET: 44992\n",
      "OFFSET: 45120\n",
      "OFFSET: 45248\n",
      "OFFSET: 45376\n",
      "OFFSET: 45504\n",
      "OFFSET: 45632\n",
      "OFFSET: 45760\n",
      "OFFSET: 45888\n",
      "OFFSET: 46016\n",
      "OFFSET: 46144\n",
      "OFFSET: 46272\n",
      "OFFSET: 46400\n",
      "OFFSET: 46528\n",
      "OFFSET: 46656\n",
      "OFFSET: 46784\n",
      "OFFSET: 46912\n",
      "OFFSET: 47040\n",
      "OFFSET: 47168\n",
      "OFFSET: 47296\n",
      "OFFSET: 47424\n",
      "OFFSET: 47552\n",
      "OFFSET: 47680\n",
      "OFFSET: 47808\n",
      "OFFSET: 47936\n",
      "OFFSET: 48064\n",
      "OFFSET: 48192\n",
      "OFFSET: 48320\n",
      "OFFSET: 48448\n",
      "OFFSET: 48576\n",
      "OFFSET: 48704\n",
      "OFFSET: 48832\n",
      "OFFSET: 48960\n",
      "OFFSET: 49088\n",
      "OFFSET: 49216\n",
      "OFFSET: 49344\n",
      "OFFSET: 49472\n",
      "OFFSET: 49600\n",
      "OFFSET: 49728\n",
      "OFFSET: 49856\n",
      "OFFSET: 49984\n",
      "OFFSET: 50112\n",
      "OFFSET: 50240\n",
      "OFFSET: 50368\n",
      "OFFSET: 50496\n",
      "OFFSET: 50624\n",
      "OFFSET: 50752\n",
      "OFFSET: 50880\n",
      "OFFSET: 51008\n",
      "OFFSET: 51136\n",
      "OFFSET: 51264\n",
      "OFFSET: 51392\n",
      "OFFSET: 51520\n",
      "OFFSET: 51648\n",
      "OFFSET: 51776\n",
      "OFFSET: 51904\n",
      "OFFSET: 52032\n",
      "OFFSET: 52160\n",
      "OFFSET: 52288\n",
      "OFFSET: 52416\n",
      "OFFSET: 52544\n",
      "OFFSET: 52672\n",
      "OFFSET: 52800\n",
      "OFFSET: 52928\n",
      "OFFSET: 53056\n",
      "OFFSET: 53184\n",
      "OFFSET: 53312\n",
      "OFFSET: 53440\n",
      "OFFSET: 53568\n",
      "OFFSET: 53696\n",
      "OFFSET: 53824\n",
      "OFFSET: 53952\n",
      "OFFSET: 54080\n",
      "OFFSET: 54208\n",
      "OFFSET: 54336\n",
      "OFFSET: 54464\n",
      "OFFSET: 54592\n",
      "OFFSET: 54720\n",
      "OFFSET: 54848\n",
      "OFFSET: 54976\n",
      "OFFSET: 55104\n",
      "OFFSET: 55232\n",
      "OFFSET: 55360\n",
      "OFFSET: 55488\n",
      "OFFSET: 55616\n",
      "OFFSET: 55744\n",
      "OFFSET: 55872\n",
      "OFFSET: 56000\n",
      "OFFSET: 56128\n",
      "Minibatch loss at step 2000: 0.941153\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 77.6%\n",
      "OFFSET: 56256\n",
      "OFFSET: 56384\n",
      "OFFSET: 56512\n",
      "OFFSET: 56640\n",
      "OFFSET: 56768\n",
      "OFFSET: 56896\n",
      "OFFSET: 57024\n",
      "OFFSET: 57152\n",
      "OFFSET: 57280\n",
      "OFFSET: 57408\n",
      "OFFSET: 57536\n",
      "OFFSET: 57664\n",
      "OFFSET: 57792\n",
      "OFFSET: 57920\n",
      "OFFSET: 58048\n",
      "OFFSET: 58176\n",
      "OFFSET: 58304\n",
      "OFFSET: 58432\n",
      "OFFSET: 58560\n",
      "OFFSET: 58688\n",
      "OFFSET: 58816\n",
      "OFFSET: 58944\n",
      "OFFSET: 59072\n",
      "OFFSET: 59200\n",
      "OFFSET: 59328\n",
      "OFFSET: 59456\n",
      "OFFSET: 59584\n",
      "OFFSET: 59712\n",
      "OFFSET: 59840\n",
      "OFFSET: 59968\n",
      "OFFSET: 60096\n",
      "OFFSET: 60224\n",
      "OFFSET: 60352\n",
      "OFFSET: 60480\n",
      "OFFSET: 60608\n",
      "OFFSET: 60736\n",
      "OFFSET: 60864\n",
      "OFFSET: 60992\n",
      "OFFSET: 61120\n",
      "OFFSET: 61248\n",
      "OFFSET: 61376\n",
      "OFFSET: 61504\n",
      "OFFSET: 61632\n",
      "OFFSET: 61760\n",
      "OFFSET: 61888\n",
      "OFFSET: 62016\n",
      "OFFSET: 62144\n",
      "OFFSET: 62272\n",
      "OFFSET: 62400\n",
      "OFFSET: 62528\n",
      "OFFSET: 62656\n",
      "OFFSET: 62784\n",
      "OFFSET: 62912\n",
      "OFFSET: 63040\n",
      "OFFSET: 63168\n",
      "OFFSET: 63296\n",
      "OFFSET: 63424\n",
      "OFFSET: 63552\n",
      "OFFSET: 63680\n",
      "OFFSET: 63808\n",
      "OFFSET: 63936\n",
      "OFFSET: 64064\n",
      "OFFSET: 64192\n",
      "OFFSET: 64320\n",
      "OFFSET: 64448\n",
      "OFFSET: 64576\n",
      "OFFSET: 64704\n",
      "OFFSET: 64832\n",
      "OFFSET: 64960\n",
      "OFFSET: 65088\n",
      "OFFSET: 65216\n",
      "OFFSET: 65344\n",
      "OFFSET: 65472\n",
      "OFFSET: 65600\n",
      "OFFSET: 65728\n",
      "OFFSET: 65856\n",
      "OFFSET: 65984\n",
      "OFFSET: 66112\n",
      "OFFSET: 66240\n",
      "OFFSET: 66368\n",
      "OFFSET: 66496\n",
      "OFFSET: 66624\n",
      "OFFSET: 66752\n",
      "OFFSET: 66880\n",
      "OFFSET: 67008\n",
      "OFFSET: 67136\n",
      "OFFSET: 67264\n",
      "OFFSET: 67392\n",
      "OFFSET: 67520\n",
      "OFFSET: 67648\n",
      "OFFSET: 67776\n",
      "OFFSET: 67904\n",
      "OFFSET: 68032\n",
      "OFFSET: 68160\n",
      "OFFSET: 68288\n",
      "OFFSET: 68416\n",
      "OFFSET: 68544\n",
      "OFFSET: 68672\n",
      "OFFSET: 68800\n",
      "OFFSET: 68928\n",
      "OFFSET: 69056\n",
      "OFFSET: 69184\n",
      "OFFSET: 69312\n",
      "OFFSET: 69440\n",
      "OFFSET: 69568\n",
      "OFFSET: 69696\n",
      "OFFSET: 69824\n",
      "OFFSET: 69952\n",
      "OFFSET: 70080\n",
      "OFFSET: 70208\n",
      "OFFSET: 70336\n",
      "OFFSET: 70464\n",
      "OFFSET: 70592\n",
      "OFFSET: 70720\n",
      "OFFSET: 70848\n",
      "OFFSET: 70976\n",
      "OFFSET: 71104\n",
      "OFFSET: 71232\n",
      "OFFSET: 71360\n",
      "OFFSET: 71488\n",
      "OFFSET: 71616\n",
      "OFFSET: 71744\n",
      "OFFSET: 71872\n",
      "OFFSET: 72000\n",
      "OFFSET: 72128\n",
      "OFFSET: 72256\n",
      "OFFSET: 72384\n",
      "OFFSET: 72512\n",
      "OFFSET: 72640\n",
      "OFFSET: 72768\n",
      "OFFSET: 72896\n",
      "OFFSET: 73024\n",
      "OFFSET: 73152\n",
      "OFFSET: 73280\n",
      "OFFSET: 73408\n",
      "OFFSET: 73536\n",
      "OFFSET: 73664\n",
      "OFFSET: 73792\n",
      "OFFSET: 73920\n",
      "OFFSET: 74048\n",
      "OFFSET: 74176\n",
      "OFFSET: 74304\n",
      "OFFSET: 74432\n",
      "OFFSET: 74560\n",
      "OFFSET: 74688\n",
      "OFFSET: 74816\n",
      "OFFSET: 74944\n",
      "OFFSET: 75072\n",
      "OFFSET: 75200\n",
      "OFFSET: 75328\n",
      "OFFSET: 75456\n",
      "OFFSET: 75584\n",
      "OFFSET: 75712\n",
      "OFFSET: 75840\n",
      "OFFSET: 75968\n",
      "OFFSET: 76096\n",
      "OFFSET: 76224\n",
      "OFFSET: 76352\n",
      "OFFSET: 76480\n",
      "OFFSET: 76608\n",
      "OFFSET: 76736\n",
      "OFFSET: 76864\n",
      "OFFSET: 76992\n",
      "OFFSET: 77120\n",
      "OFFSET: 77248\n",
      "OFFSET: 77376\n",
      "OFFSET: 77504\n",
      "OFFSET: 77632\n",
      "OFFSET: 77760\n",
      "OFFSET: 77888\n",
      "OFFSET: 78016\n",
      "OFFSET: 78144\n",
      "OFFSET: 78272\n",
      "OFFSET: 78400\n",
      "OFFSET: 78528\n",
      "OFFSET: 78656\n",
      "OFFSET: 78784\n",
      "OFFSET: 78912\n",
      "OFFSET: 79040\n",
      "OFFSET: 79168\n",
      "OFFSET: 79296\n",
      "OFFSET: 79424\n",
      "OFFSET: 79552\n",
      "OFFSET: 79680\n",
      "OFFSET: 79808\n",
      "OFFSET: 79936\n",
      "OFFSET: 80064\n",
      "OFFSET: 80192\n",
      "OFFSET: 80320\n",
      "OFFSET: 80448\n",
      "OFFSET: 80576\n",
      "OFFSET: 80704\n",
      "OFFSET: 80832\n",
      "OFFSET: 80960\n",
      "OFFSET: 81088\n",
      "OFFSET: 81216\n",
      "OFFSET: 81344\n",
      "OFFSET: 81472\n",
      "OFFSET: 81600\n",
      "OFFSET: 81728\n",
      "OFFSET: 81856\n",
      "OFFSET: 81984\n",
      "OFFSET: 82112\n",
      "OFFSET: 82240\n",
      "OFFSET: 82368\n",
      "OFFSET: 82496\n",
      "OFFSET: 82624\n",
      "OFFSET: 82752\n",
      "OFFSET: 82880\n",
      "OFFSET: 83008\n",
      "OFFSET: 83136\n",
      "OFFSET: 83264\n",
      "OFFSET: 83392\n",
      "OFFSET: 83520\n",
      "OFFSET: 83648\n",
      "OFFSET: 83776\n",
      "OFFSET: 83904\n",
      "OFFSET: 84032\n",
      "OFFSET: 84160\n",
      "OFFSET: 84288\n",
      "OFFSET: 84416\n",
      "OFFSET: 84544\n",
      "OFFSET: 84672\n",
      "OFFSET: 84800\n",
      "OFFSET: 84928\n",
      "OFFSET: 85056\n",
      "OFFSET: 85184\n",
      "OFFSET: 85312\n",
      "OFFSET: 85440\n",
      "OFFSET: 85568\n",
      "OFFSET: 85696\n",
      "OFFSET: 85824\n",
      "OFFSET: 85952\n",
      "OFFSET: 86080\n",
      "OFFSET: 86208\n",
      "OFFSET: 86336\n",
      "OFFSET: 86464\n",
      "OFFSET: 86592\n",
      "OFFSET: 86720\n",
      "OFFSET: 86848\n",
      "OFFSET: 86976\n",
      "OFFSET: 87104\n",
      "OFFSET: 87232\n",
      "OFFSET: 87360\n",
      "OFFSET: 87488\n",
      "OFFSET: 87616\n",
      "OFFSET: 87744\n",
      "OFFSET: 87872\n",
      "OFFSET: 88000\n",
      "OFFSET: 88128\n",
      "OFFSET: 88256\n",
      "OFFSET: 88384\n",
      "OFFSET: 88512\n",
      "OFFSET: 88640\n",
      "OFFSET: 88768\n",
      "OFFSET: 88896\n",
      "OFFSET: 89024\n",
      "OFFSET: 89152\n",
      "OFFSET: 89280\n",
      "OFFSET: 89408\n",
      "OFFSET: 89536\n",
      "OFFSET: 89664\n",
      "OFFSET: 89792\n",
      "OFFSET: 89920\n",
      "OFFSET: 90048\n",
      "OFFSET: 90176\n",
      "OFFSET: 90304\n",
      "OFFSET: 90432\n",
      "OFFSET: 90560\n",
      "OFFSET: 90688\n",
      "OFFSET: 90816\n",
      "OFFSET: 90944\n",
      "OFFSET: 91072\n",
      "OFFSET: 91200\n",
      "OFFSET: 91328\n",
      "OFFSET: 91456\n",
      "OFFSET: 91584\n",
      "OFFSET: 91712\n",
      "OFFSET: 91840\n",
      "OFFSET: 91968\n",
      "OFFSET: 92096\n",
      "OFFSET: 92224\n",
      "OFFSET: 92352\n",
      "OFFSET: 92480\n",
      "OFFSET: 92608\n",
      "OFFSET: 92736\n",
      "OFFSET: 92864\n",
      "OFFSET: 92992\n",
      "OFFSET: 93120\n",
      "OFFSET: 93248\n",
      "OFFSET: 93376\n",
      "OFFSET: 93504\n",
      "OFFSET: 93632\n",
      "OFFSET: 93760\n",
      "OFFSET: 93888\n",
      "OFFSET: 94016\n",
      "OFFSET: 94144\n",
      "OFFSET: 94272\n",
      "OFFSET: 94400\n",
      "OFFSET: 94528\n",
      "OFFSET: 94656\n",
      "OFFSET: 94784\n",
      "OFFSET: 94912\n",
      "OFFSET: 95040\n",
      "OFFSET: 95168\n",
      "OFFSET: 95296\n",
      "OFFSET: 95424\n",
      "OFFSET: 95552\n",
      "OFFSET: 95680\n",
      "OFFSET: 95808\n",
      "OFFSET: 95936\n",
      "OFFSET: 96064\n",
      "OFFSET: 96192\n",
      "OFFSET: 96320\n",
      "OFFSET: 96448\n",
      "OFFSET: 96576\n",
      "OFFSET: 96704\n",
      "OFFSET: 96832\n",
      "OFFSET: 96960\n",
      "OFFSET: 97088\n",
      "OFFSET: 97216\n",
      "OFFSET: 97344\n",
      "OFFSET: 97472\n",
      "OFFSET: 97600\n",
      "OFFSET: 97728\n",
      "OFFSET: 97856\n",
      "OFFSET: 97984\n",
      "OFFSET: 98112\n",
      "OFFSET: 98240\n",
      "OFFSET: 98368\n",
      "OFFSET: 98496\n",
      "OFFSET: 98624\n",
      "OFFSET: 98752\n",
      "OFFSET: 98880\n",
      "OFFSET: 99008\n",
      "OFFSET: 99136\n",
      "OFFSET: 99264\n",
      "OFFSET: 99392\n",
      "OFFSET: 99520\n",
      "OFFSET: 99648\n",
      "OFFSET: 99776\n",
      "OFFSET: 99904\n",
      "OFFSET: 100032\n",
      "OFFSET: 100160\n",
      "OFFSET: 100288\n",
      "OFFSET: 100416\n",
      "OFFSET: 100544\n",
      "OFFSET: 100672\n",
      "OFFSET: 100800\n",
      "OFFSET: 100928\n",
      "OFFSET: 101056\n",
      "OFFSET: 101184\n",
      "OFFSET: 101312\n",
      "OFFSET: 101440\n",
      "OFFSET: 101568\n",
      "OFFSET: 101696\n",
      "OFFSET: 101824\n",
      "OFFSET: 101952\n",
      "OFFSET: 102080\n",
      "OFFSET: 102208\n",
      "OFFSET: 102336\n",
      "OFFSET: 102464\n",
      "OFFSET: 102592\n",
      "OFFSET: 102720\n",
      "OFFSET: 102848\n",
      "OFFSET: 102976\n",
      "OFFSET: 103104\n",
      "OFFSET: 103232\n",
      "OFFSET: 103360\n",
      "OFFSET: 103488\n",
      "OFFSET: 103616\n",
      "OFFSET: 103744\n",
      "OFFSET: 103872\n",
      "OFFSET: 104000\n",
      "OFFSET: 104128\n",
      "OFFSET: 104256\n",
      "OFFSET: 104384\n",
      "OFFSET: 104512\n",
      "OFFSET: 104640\n",
      "OFFSET: 104768\n",
      "OFFSET: 104896\n",
      "OFFSET: 105024\n",
      "OFFSET: 105152\n",
      "OFFSET: 105280\n",
      "OFFSET: 105408\n",
      "OFFSET: 105536\n",
      "OFFSET: 105664\n",
      "OFFSET: 105792\n",
      "OFFSET: 105920\n",
      "OFFSET: 106048\n",
      "OFFSET: 106176\n",
      "OFFSET: 106304\n",
      "OFFSET: 106432\n",
      "OFFSET: 106560\n",
      "OFFSET: 106688\n",
      "OFFSET: 106816\n",
      "OFFSET: 106944\n",
      "OFFSET: 107072\n",
      "OFFSET: 107200\n",
      "OFFSET: 107328\n",
      "OFFSET: 107456\n",
      "OFFSET: 107584\n",
      "OFFSET: 107712\n",
      "OFFSET: 107840\n",
      "OFFSET: 107968\n",
      "OFFSET: 108096\n",
      "OFFSET: 108224\n",
      "OFFSET: 108352\n",
      "OFFSET: 108480\n",
      "OFFSET: 108608\n",
      "OFFSET: 108736\n",
      "OFFSET: 108864\n",
      "OFFSET: 108992\n",
      "OFFSET: 109120\n",
      "OFFSET: 109248\n",
      "OFFSET: 109376\n",
      "OFFSET: 109504\n",
      "OFFSET: 109632\n",
      "OFFSET: 109760\n",
      "OFFSET: 109888\n",
      "OFFSET: 110016\n",
      "OFFSET: 110144\n",
      "OFFSET: 110272\n",
      "OFFSET: 110400\n",
      "OFFSET: 110528\n",
      "OFFSET: 110656\n",
      "OFFSET: 110784\n",
      "OFFSET: 110912\n",
      "OFFSET: 111040\n",
      "OFFSET: 111168\n",
      "OFFSET: 111296\n",
      "OFFSET: 111424\n",
      "OFFSET: 111552\n",
      "OFFSET: 111680\n",
      "OFFSET: 111808\n",
      "OFFSET: 111936\n",
      "OFFSET: 112064\n",
      "OFFSET: 112192\n",
      "OFFSET: 112320\n",
      "OFFSET: 112448\n",
      "OFFSET: 112576\n",
      "OFFSET: 112704\n",
      "OFFSET: 112832\n",
      "OFFSET: 112960\n",
      "OFFSET: 113088\n",
      "OFFSET: 113216\n",
      "OFFSET: 113344\n",
      "OFFSET: 113472\n",
      "OFFSET: 113600\n",
      "OFFSET: 113728\n",
      "OFFSET: 113856\n",
      "OFFSET: 113984\n",
      "OFFSET: 114112\n",
      "OFFSET: 114240\n",
      "OFFSET: 114368\n",
      "OFFSET: 114496\n",
      "OFFSET: 114624\n",
      "OFFSET: 114752\n",
      "OFFSET: 114880\n",
      "OFFSET: 115008\n",
      "OFFSET: 115136\n",
      "OFFSET: 115264\n",
      "OFFSET: 115392\n",
      "OFFSET: 115520\n",
      "OFFSET: 115648\n",
      "OFFSET: 115776\n",
      "OFFSET: 115904\n",
      "OFFSET: 116032\n",
      "OFFSET: 116160\n",
      "OFFSET: 116288\n",
      "OFFSET: 116416\n",
      "OFFSET: 116544\n",
      "OFFSET: 116672\n",
      "OFFSET: 116800\n",
      "OFFSET: 116928\n",
      "OFFSET: 117056\n",
      "OFFSET: 117184\n",
      "OFFSET: 117312\n",
      "OFFSET: 117440\n",
      "OFFSET: 117568\n",
      "OFFSET: 117696\n",
      "OFFSET: 117824\n",
      "OFFSET: 117952\n",
      "OFFSET: 118080\n",
      "OFFSET: 118208\n",
      "OFFSET: 118336\n",
      "OFFSET: 118464\n",
      "OFFSET: 118592\n",
      "OFFSET: 118720\n",
      "OFFSET: 118848\n",
      "OFFSET: 118976\n",
      "OFFSET: 119104\n",
      "OFFSET: 119232\n",
      "OFFSET: 119360\n",
      "OFFSET: 119488\n",
      "OFFSET: 119616\n",
      "OFFSET: 119744\n",
      "OFFSET: 119872\n",
      "OFFSET: 120000\n",
      "OFFSET: 120128\n",
      "Minibatch loss at step 2500: 1.169946\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 78.0%\n",
      "OFFSET: 120256\n",
      "OFFSET: 120384\n",
      "OFFSET: 120512\n",
      "OFFSET: 120640\n",
      "OFFSET: 120768\n",
      "OFFSET: 120896\n",
      "OFFSET: 121024\n",
      "OFFSET: 121152\n",
      "OFFSET: 121280\n",
      "OFFSET: 121408\n",
      "OFFSET: 121536\n",
      "OFFSET: 121664\n",
      "OFFSET: 121792\n",
      "OFFSET: 121920\n",
      "OFFSET: 122048\n",
      "OFFSET: 122176\n",
      "OFFSET: 122304\n",
      "OFFSET: 122432\n",
      "OFFSET: 122560\n",
      "OFFSET: 122688\n",
      "OFFSET: 122816\n",
      "OFFSET: 122944\n",
      "OFFSET: 123072\n",
      "OFFSET: 123200\n",
      "OFFSET: 123328\n",
      "OFFSET: 123456\n",
      "OFFSET: 123584\n",
      "OFFSET: 123712\n",
      "OFFSET: 123840\n",
      "OFFSET: 123968\n",
      "OFFSET: 124096\n",
      "OFFSET: 124224\n",
      "OFFSET: 124352\n",
      "OFFSET: 124480\n",
      "OFFSET: 124608\n",
      "OFFSET: 124736\n",
      "OFFSET: 124864\n",
      "OFFSET: 124992\n",
      "OFFSET: 125120\n",
      "OFFSET: 125248\n",
      "OFFSET: 125376\n",
      "OFFSET: 125504\n",
      "OFFSET: 125632\n",
      "OFFSET: 125760\n",
      "OFFSET: 125888\n",
      "OFFSET: 126016\n",
      "OFFSET: 126144\n",
      "OFFSET: 126272\n",
      "OFFSET: 126400\n",
      "OFFSET: 126528\n",
      "OFFSET: 126656\n",
      "OFFSET: 126784\n",
      "OFFSET: 126912\n",
      "OFFSET: 127040\n",
      "OFFSET: 127168\n",
      "OFFSET: 127296\n",
      "OFFSET: 127424\n",
      "OFFSET: 127552\n",
      "OFFSET: 127680\n",
      "OFFSET: 127808\n",
      "OFFSET: 127936\n",
      "OFFSET: 128064\n",
      "OFFSET: 128192\n",
      "OFFSET: 128320\n",
      "OFFSET: 128448\n",
      "OFFSET: 128576\n",
      "OFFSET: 128704\n",
      "OFFSET: 128832\n",
      "OFFSET: 128960\n",
      "OFFSET: 129088\n",
      "OFFSET: 129216\n",
      "OFFSET: 129344\n",
      "OFFSET: 129472\n",
      "OFFSET: 129600\n",
      "OFFSET: 129728\n",
      "OFFSET: 129856\n",
      "OFFSET: 129984\n",
      "OFFSET: 130112\n",
      "OFFSET: 130240\n",
      "OFFSET: 130368\n",
      "OFFSET: 130496\n",
      "OFFSET: 130624\n",
      "OFFSET: 130752\n",
      "OFFSET: 130880\n",
      "OFFSET: 131008\n",
      "OFFSET: 131136\n",
      "OFFSET: 131264\n",
      "OFFSET: 131392\n",
      "OFFSET: 131520\n",
      "OFFSET: 131648\n",
      "OFFSET: 131776\n",
      "OFFSET: 131904\n",
      "OFFSET: 132032\n",
      "OFFSET: 132160\n",
      "OFFSET: 132288\n",
      "OFFSET: 132416\n",
      "OFFSET: 132544\n",
      "OFFSET: 132672\n",
      "OFFSET: 132800\n",
      "OFFSET: 132928\n",
      "OFFSET: 133056\n",
      "OFFSET: 133184\n",
      "OFFSET: 133312\n",
      "OFFSET: 133440\n",
      "OFFSET: 133568\n",
      "OFFSET: 133696\n",
      "OFFSET: 133824\n",
      "OFFSET: 133952\n",
      "OFFSET: 134080\n",
      "OFFSET: 134208\n",
      "OFFSET: 134336\n",
      "OFFSET: 134464\n",
      "OFFSET: 134592\n",
      "OFFSET: 134720\n",
      "OFFSET: 134848\n",
      "OFFSET: 134976\n",
      "OFFSET: 135104\n",
      "OFFSET: 135232\n",
      "OFFSET: 135360\n",
      "OFFSET: 135488\n",
      "OFFSET: 135616\n",
      "OFFSET: 135744\n",
      "OFFSET: 135872\n",
      "OFFSET: 136000\n",
      "OFFSET: 136128\n",
      "OFFSET: 136256\n",
      "OFFSET: 136384\n",
      "OFFSET: 136512\n",
      "OFFSET: 136640\n",
      "OFFSET: 136768\n",
      "OFFSET: 136896\n",
      "OFFSET: 137024\n",
      "OFFSET: 137152\n",
      "OFFSET: 137280\n",
      "OFFSET: 137408\n",
      "OFFSET: 137536\n",
      "OFFSET: 137664\n",
      "OFFSET: 137792\n",
      "OFFSET: 137920\n",
      "OFFSET: 138048\n",
      "OFFSET: 138176\n",
      "OFFSET: 138304\n",
      "OFFSET: 138432\n",
      "OFFSET: 138560\n",
      "OFFSET: 138688\n",
      "OFFSET: 138816\n",
      "OFFSET: 138944\n",
      "OFFSET: 139072\n",
      "OFFSET: 139200\n",
      "OFFSET: 139328\n",
      "OFFSET: 139456\n",
      "OFFSET: 139584\n",
      "OFFSET: 139712\n",
      "OFFSET: 139840\n",
      "OFFSET: 139968\n",
      "OFFSET: 140096\n",
      "OFFSET: 140224\n",
      "OFFSET: 140352\n",
      "OFFSET: 140480\n",
      "OFFSET: 140608\n",
      "OFFSET: 140736\n",
      "OFFSET: 140864\n",
      "OFFSET: 140992\n",
      "OFFSET: 141120\n",
      "OFFSET: 141248\n",
      "OFFSET: 141376\n",
      "OFFSET: 141504\n",
      "OFFSET: 141632\n",
      "OFFSET: 141760\n",
      "OFFSET: 141888\n",
      "OFFSET: 142016\n",
      "OFFSET: 142144\n",
      "OFFSET: 142272\n",
      "OFFSET: 142400\n",
      "OFFSET: 142528\n",
      "OFFSET: 142656\n",
      "OFFSET: 142784\n",
      "OFFSET: 142912\n",
      "OFFSET: 143040\n",
      "OFFSET: 143168\n",
      "OFFSET: 143296\n",
      "OFFSET: 143424\n",
      "OFFSET: 143552\n",
      "OFFSET: 143680\n",
      "OFFSET: 143808\n",
      "OFFSET: 143936\n",
      "OFFSET: 144064\n",
      "OFFSET: 144192\n",
      "OFFSET: 144320\n",
      "OFFSET: 144448\n",
      "OFFSET: 144576\n",
      "OFFSET: 144704\n",
      "OFFSET: 144832\n",
      "OFFSET: 144960\n",
      "OFFSET: 145088\n",
      "OFFSET: 145216\n",
      "OFFSET: 145344\n",
      "OFFSET: 145472\n",
      "OFFSET: 145600\n",
      "OFFSET: 145728\n",
      "OFFSET: 145856\n",
      "OFFSET: 145984\n",
      "OFFSET: 146112\n",
      "OFFSET: 146240\n",
      "OFFSET: 146368\n",
      "OFFSET: 146496\n",
      "OFFSET: 146624\n",
      "OFFSET: 146752\n",
      "OFFSET: 146880\n",
      "OFFSET: 147008\n",
      "OFFSET: 147136\n",
      "OFFSET: 147264\n",
      "OFFSET: 147392\n",
      "OFFSET: 147520\n",
      "OFFSET: 147648\n",
      "OFFSET: 147776\n",
      "OFFSET: 147904\n",
      "OFFSET: 148032\n",
      "OFFSET: 148160\n",
      "OFFSET: 148288\n",
      "OFFSET: 148416\n",
      "OFFSET: 148544\n",
      "OFFSET: 148672\n",
      "OFFSET: 148800\n",
      "OFFSET: 148928\n",
      "OFFSET: 149056\n",
      "OFFSET: 149184\n",
      "OFFSET: 149312\n",
      "OFFSET: 149440\n",
      "OFFSET: 149568\n",
      "OFFSET: 149696\n",
      "OFFSET: 149824\n",
      "OFFSET: 149952\n",
      "OFFSET: 150080\n",
      "OFFSET: 150208\n",
      "OFFSET: 150336\n",
      "OFFSET: 150464\n",
      "OFFSET: 150592\n",
      "OFFSET: 150720\n",
      "OFFSET: 150848\n",
      "OFFSET: 150976\n",
      "OFFSET: 151104\n",
      "OFFSET: 151232\n",
      "OFFSET: 151360\n",
      "OFFSET: 151488\n",
      "OFFSET: 151616\n",
      "OFFSET: 151744\n",
      "OFFSET: 151872\n",
      "OFFSET: 152000\n",
      "OFFSET: 152128\n",
      "OFFSET: 152256\n",
      "OFFSET: 152384\n",
      "OFFSET: 152512\n",
      "OFFSET: 152640\n",
      "OFFSET: 152768\n",
      "OFFSET: 152896\n",
      "OFFSET: 153024\n",
      "OFFSET: 153152\n",
      "OFFSET: 153280\n",
      "OFFSET: 153408\n",
      "OFFSET: 153536\n",
      "OFFSET: 153664\n",
      "OFFSET: 153792\n",
      "OFFSET: 153920\n",
      "OFFSET: 154048\n",
      "OFFSET: 154176\n",
      "OFFSET: 154304\n",
      "OFFSET: 154432\n",
      "OFFSET: 154560\n",
      "OFFSET: 154688\n",
      "OFFSET: 154816\n",
      "OFFSET: 154944\n",
      "OFFSET: 155072\n",
      "OFFSET: 155200\n",
      "OFFSET: 155328\n",
      "OFFSET: 155456\n",
      "OFFSET: 155584\n",
      "OFFSET: 155712\n",
      "OFFSET: 155840\n",
      "OFFSET: 155968\n",
      "OFFSET: 156096\n",
      "OFFSET: 156224\n",
      "OFFSET: 156352\n",
      "OFFSET: 156480\n",
      "OFFSET: 156608\n",
      "OFFSET: 156736\n",
      "OFFSET: 156864\n",
      "OFFSET: 156992\n",
      "OFFSET: 157120\n",
      "OFFSET: 157248\n",
      "OFFSET: 157376\n",
      "OFFSET: 157504\n",
      "OFFSET: 157632\n",
      "OFFSET: 157760\n",
      "OFFSET: 157888\n",
      "OFFSET: 158016\n",
      "OFFSET: 158144\n",
      "OFFSET: 158272\n",
      "OFFSET: 158400\n",
      "OFFSET: 158528\n",
      "OFFSET: 158656\n",
      "OFFSET: 158784\n",
      "OFFSET: 158912\n",
      "OFFSET: 159040\n",
      "OFFSET: 159168\n",
      "OFFSET: 159296\n",
      "OFFSET: 159424\n",
      "OFFSET: 159552\n",
      "OFFSET: 159680\n",
      "OFFSET: 159808\n",
      "OFFSET: 159936\n",
      "OFFSET: 160064\n",
      "OFFSET: 160192\n",
      "OFFSET: 160320\n",
      "OFFSET: 160448\n",
      "OFFSET: 160576\n",
      "OFFSET: 160704\n",
      "OFFSET: 160832\n",
      "OFFSET: 160960\n",
      "OFFSET: 161088\n",
      "OFFSET: 161216\n",
      "OFFSET: 161344\n",
      "OFFSET: 161472\n",
      "OFFSET: 161600\n",
      "OFFSET: 161728\n",
      "OFFSET: 161856\n",
      "OFFSET: 161984\n",
      "OFFSET: 162112\n",
      "OFFSET: 162240\n",
      "OFFSET: 162368\n",
      "OFFSET: 162496\n",
      "OFFSET: 162624\n",
      "OFFSET: 162752\n",
      "OFFSET: 162880\n",
      "OFFSET: 163008\n",
      "OFFSET: 163136\n",
      "OFFSET: 163264\n",
      "OFFSET: 163392\n",
      "OFFSET: 163520\n",
      "OFFSET: 163648\n",
      "OFFSET: 163776\n",
      "OFFSET: 163904\n",
      "OFFSET: 164032\n",
      "OFFSET: 164160\n",
      "OFFSET: 164288\n",
      "OFFSET: 164416\n",
      "OFFSET: 164544\n",
      "OFFSET: 164672\n",
      "OFFSET: 164800\n",
      "OFFSET: 164928\n",
      "OFFSET: 165056\n",
      "OFFSET: 165184\n",
      "OFFSET: 165312\n",
      "OFFSET: 165440\n",
      "OFFSET: 165568\n",
      "OFFSET: 165696\n",
      "OFFSET: 165824\n",
      "OFFSET: 165952\n",
      "OFFSET: 166080\n",
      "OFFSET: 166208\n",
      "OFFSET: 166336\n",
      "OFFSET: 166464\n",
      "OFFSET: 166592\n",
      "OFFSET: 166720\n",
      "OFFSET: 166848\n",
      "OFFSET: 166976\n",
      "OFFSET: 167104\n",
      "OFFSET: 167232\n",
      "OFFSET: 167360\n",
      "OFFSET: 167488\n",
      "OFFSET: 167616\n",
      "OFFSET: 167744\n",
      "OFFSET: 167872\n",
      "OFFSET: 168000\n",
      "OFFSET: 168128\n",
      "OFFSET: 168256\n",
      "OFFSET: 168384\n",
      "OFFSET: 168512\n",
      "OFFSET: 168640\n",
      "OFFSET: 168768\n",
      "OFFSET: 168896\n",
      "OFFSET: 169024\n",
      "OFFSET: 169152\n",
      "OFFSET: 169280\n",
      "OFFSET: 169408\n",
      "OFFSET: 169536\n",
      "OFFSET: 169664\n",
      "OFFSET: 169792\n",
      "OFFSET: 169920\n",
      "OFFSET: 170048\n",
      "OFFSET: 170176\n",
      "OFFSET: 170304\n",
      "OFFSET: 170432\n",
      "OFFSET: 170560\n",
      "OFFSET: 170688\n",
      "OFFSET: 170816\n",
      "OFFSET: 170944\n",
      "OFFSET: 171072\n",
      "OFFSET: 171200\n",
      "OFFSET: 171328\n",
      "OFFSET: 171456\n",
      "OFFSET: 171584\n",
      "OFFSET: 171712\n",
      "OFFSET: 171840\n",
      "OFFSET: 171968\n",
      "OFFSET: 172096\n",
      "OFFSET: 172224\n",
      "OFFSET: 172352\n",
      "OFFSET: 172480\n",
      "OFFSET: 172608\n",
      "OFFSET: 172736\n",
      "OFFSET: 172864\n",
      "OFFSET: 172992\n",
      "OFFSET: 173120\n",
      "OFFSET: 173248\n",
      "OFFSET: 173376\n",
      "OFFSET: 173504\n",
      "OFFSET: 173632\n",
      "OFFSET: 173760\n",
      "OFFSET: 173888\n",
      "OFFSET: 174016\n",
      "OFFSET: 174144\n",
      "OFFSET: 174272\n",
      "OFFSET: 174400\n",
      "OFFSET: 174528\n",
      "OFFSET: 174656\n",
      "OFFSET: 174784\n",
      "OFFSET: 174912\n",
      "OFFSET: 175040\n",
      "OFFSET: 175168\n",
      "OFFSET: 175296\n",
      "OFFSET: 175424\n",
      "OFFSET: 175552\n",
      "OFFSET: 175680\n",
      "OFFSET: 175808\n",
      "OFFSET: 175936\n",
      "OFFSET: 176064\n",
      "OFFSET: 176192\n",
      "OFFSET: 176320\n",
      "OFFSET: 176448\n",
      "OFFSET: 176576\n",
      "OFFSET: 176704\n",
      "OFFSET: 176832\n",
      "OFFSET: 176960\n",
      "OFFSET: 177088\n",
      "OFFSET: 177216\n",
      "OFFSET: 177344\n",
      "OFFSET: 177472\n",
      "OFFSET: 177600\n",
      "OFFSET: 177728\n",
      "OFFSET: 177856\n",
      "OFFSET: 177984\n",
      "OFFSET: 178112\n",
      "OFFSET: 178240\n",
      "OFFSET: 178368\n",
      "OFFSET: 178496\n",
      "OFFSET: 178624\n",
      "OFFSET: 178752\n",
      "OFFSET: 178880\n",
      "OFFSET: 179008\n",
      "OFFSET: 179136\n",
      "OFFSET: 179264\n",
      "OFFSET: 179392\n",
      "OFFSET: 179520\n",
      "OFFSET: 179648\n",
      "OFFSET: 179776\n",
      "OFFSET: 179904\n",
      "OFFSET: 180032\n",
      "OFFSET: 180160\n",
      "OFFSET: 180288\n",
      "OFFSET: 180416\n",
      "OFFSET: 180544\n",
      "OFFSET: 180672\n",
      "OFFSET: 180800\n",
      "OFFSET: 180928\n",
      "OFFSET: 181056\n",
      "OFFSET: 181184\n",
      "OFFSET: 181312\n",
      "OFFSET: 181440\n",
      "OFFSET: 181568\n",
      "OFFSET: 181696\n",
      "OFFSET: 181824\n",
      "OFFSET: 181952\n",
      "OFFSET: 182080\n",
      "OFFSET: 182208\n",
      "OFFSET: 182336\n",
      "OFFSET: 182464\n",
      "OFFSET: 182592\n",
      "OFFSET: 182720\n",
      "OFFSET: 182848\n",
      "OFFSET: 182976\n",
      "OFFSET: 183104\n",
      "OFFSET: 183232\n",
      "OFFSET: 183360\n",
      "OFFSET: 183488\n",
      "OFFSET: 183616\n",
      "OFFSET: 183744\n",
      "OFFSET: 183872\n",
      "OFFSET: 184000\n",
      "OFFSET: 184128\n",
      "Minibatch loss at step 3000: 1.034425\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 78.7%\n",
      "Test accuracy: 86.3%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "  \n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"Validation accuracy: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7omWxtvLLxik"
   },
   "source": [
    "---\n",
    "Problem\n",
    "-------\n",
    "\n",
    "Turn the logistic regression example with SGD into a 1-hidden layer neural network with rectified linear units [nn.relu()](https://www.tensorflow.org/versions/r0.7/api_docs/python/nn.html#relu) and 1024 hidden nodes. This model should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression example **without** SGD: 1-hidden layer neural network with rectified linear units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_relu_graph(nb_hidden):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        # Input data.\n",
    "        # Load the training, validation and test data into constants that are\n",
    "        # attached to the graph.\n",
    "        tf_train_dataset = tf.constant(train_dataset[:train_subset, :])\n",
    "        tf_train_labels = tf.constant(train_labels[:train_subset])\n",
    "        tf_valid_dataset = tf.constant(valid_dataset)\n",
    "        tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "        # hidden layer\n",
    "        weights_1 = tf.Variable(tf.truncated_normal([image_size * image_size, nb_hidden]))\n",
    "        biases_1 = tf.Variable(tf.zeros([nb_hidden]))\n",
    "        hidden = tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1)\n",
    "        \n",
    "        # output layer\n",
    "        weights_2 = tf.Variable(tf.truncated_normal([nb_hidden, num_labels]))\n",
    "        biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "        logits = tf.matmul(hidden, weights_2) + biases_2\n",
    "\n",
    "        # loss function\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  \n",
    "        # Optimizer.\n",
    "        # We are going to find the minimum of this loss using gradient descent.\n",
    "        optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "        # Predictions for the training, validation, and test data.\n",
    "        # These are not part of training, but merely here so that we can report\n",
    "        # accuracy figures as we train.\n",
    "        def compute_prediction(dataset):\n",
    "            return tf.nn.softmax(tf.matmul(tf.nn.relu(tf.matmul(dataset, weights_1) + biases_1), weights_2) + biases_2)\n",
    "        \n",
    "        train_prediction = tf.nn.softmax(logits)\n",
    "        valid_prediction = compute_prediction(tf_valid_dataset)\n",
    "        test_prediction = compute_prediction(tf_test_dataset)\n",
    "\n",
    "        return (graph, optimizer, loss, { 'train': train_prediction, 'valid': valid_prediction, 'test': test_prediction})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute accuracy for 10, 100, 500 and 1000 hidden nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initialized for 10 hidden relu\n",
      "Loss at step 0: 31.811394\n",
      "Training accuracy: 9.5%\n",
      "Validation accuracy: 15.4%\n",
      "Loss at step 100: 1.547410\n",
      "Training accuracy: 51.5%\n",
      "Validation accuracy: 54.5%\n",
      "Loss at step 200: 1.232859\n",
      "Training accuracy: 65.3%\n",
      "Validation accuracy: 61.5%\n",
      "Loss at step 300: 1.128646\n",
      "Training accuracy: 67.9%\n",
      "Validation accuracy: 66.5%\n",
      "Loss at step 400: 1.036702\n",
      "Training accuracy: 70.5%\n",
      "Validation accuracy: 69.3%\n",
      "Loss at step 500: 0.989138\n",
      "Training accuracy: 71.8%\n",
      "Validation accuracy: 71.3%\n",
      "Loss at step 600: 0.950563\n",
      "Training accuracy: 72.9%\n",
      "Validation accuracy: 72.5%\n",
      "Loss at step 700: 0.855846\n",
      "Training accuracy: 75.2%\n",
      "Validation accuracy: 74.0%\n",
      "Loss at step 800: 0.779935\n",
      "Training accuracy: 77.5%\n",
      "Validation accuracy: 75.7%\n",
      "Test accuracy: 83.2%\n",
      "CPU times: user 2min 3s, sys: 11.3 s, total: 2min 14s\n",
      "Wall time: 42 s\n",
      "\n",
      "Initialized for 100 hidden relu\n",
      "Loss at step 0: 104.505600\n",
      "Training accuracy: 13.2%\n",
      "Validation accuracy: 38.8%\n",
      "Loss at step 100: 2.523742\n",
      "Training accuracy: 79.3%\n",
      "Validation accuracy: 73.3%\n",
      "Loss at step 200: 1.414398\n",
      "Training accuracy: 79.5%\n",
      "Validation accuracy: 71.8%\n",
      "Loss at step 300: 1.032472\n",
      "Training accuracy: 81.3%\n",
      "Validation accuracy: 73.6%\n",
      "Loss at step 400: 0.758523\n",
      "Training accuracy: 84.0%\n",
      "Validation accuracy: 75.1%\n",
      "Loss at step 500: 0.642835\n",
      "Training accuracy: 85.1%\n",
      "Validation accuracy: 75.7%\n",
      "Loss at step 600: 0.564838\n",
      "Training accuracy: 86.3%\n",
      "Validation accuracy: 75.9%\n",
      "Loss at step 700: 0.532089\n",
      "Training accuracy: 86.5%\n",
      "Validation accuracy: 75.6%\n",
      "Loss at step 800: 0.445639\n",
      "Training accuracy: 88.2%\n",
      "Validation accuracy: 76.4%\n",
      "Test accuracy: 84.3%\n",
      "CPU times: user 7min 11s, sys: 14.6 s, total: 7min 26s\n",
      "Wall time: 2min 11s\n",
      "\n",
      "Initialized for 500 hidden relu\n",
      "Loss at step 0: 205.982605\n",
      "Training accuracy: 18.5%\n",
      "Validation accuracy: 27.3%\n",
      "Loss at step 100: 3.736434\n",
      "Training accuracy: 87.9%\n",
      "Validation accuracy: 77.0%\n",
      "Loss at step 200: 0.776490\n",
      "Training accuracy: 96.2%\n",
      "Validation accuracy: 77.2%\n",
      "Loss at step 300: 0.080872\n",
      "Training accuracy: 99.3%\n",
      "Validation accuracy: 76.8%\n",
      "Loss at step 400: 0.038361\n",
      "Training accuracy: 99.4%\n",
      "Validation accuracy: 77.2%\n",
      "Loss at step 500: 0.024380\n",
      "Training accuracy: 99.7%\n",
      "Validation accuracy: 77.2%\n",
      "Loss at step 600: 0.021567\n",
      "Training accuracy: 99.8%\n",
      "Validation accuracy: 77.3%\n",
      "Loss at step 700: 0.021583\n",
      "Training accuracy: 99.8%\n",
      "Validation accuracy: 77.4%\n",
      "Loss at step 800: 0.017387\n",
      "Training accuracy: 99.8%\n",
      "Validation accuracy: 77.3%\n",
      "Test accuracy: 85.3%\n",
      "CPU times: user 31min 56s, sys: 39.2 s, total: 32min 35s\n",
      "Wall time: 9min 26s\n",
      "\n",
      "Initialized for 1000 hidden relu\n",
      "Loss at step 0: 388.312897\n",
      "Training accuracy: 8.1%\n",
      "Validation accuracy: 33.6%\n",
      "Loss at step 100: 2.925992\n",
      "Training accuracy: 92.8%\n",
      "Validation accuracy: 79.3%\n",
      "Loss at step 200: 0.278343\n",
      "Training accuracy: 98.3%\n",
      "Validation accuracy: 79.1%\n",
      "Loss at step 300: 0.189879\n",
      "Training accuracy: 99.5%\n",
      "Validation accuracy: 79.6%\n",
      "Loss at step 400: 0.106625\n",
      "Training accuracy: 99.6%\n",
      "Validation accuracy: 79.7%\n",
      "Loss at step 500: 0.022371\n",
      "Training accuracy: 99.7%\n",
      "Validation accuracy: 79.7%\n",
      "Loss at step 600: 0.043524\n",
      "Training accuracy: 99.8%\n",
      "Validation accuracy: 79.7%\n",
      "Loss at step 700: 0.080199\n",
      "Training accuracy: 99.7%\n",
      "Validation accuracy: 79.7%\n",
      "Loss at step 800: 0.015155\n",
      "Training accuracy: 99.9%\n",
      "Validation accuracy: 79.5%\n",
      "Test accuracy: 86.6%\n",
      "CPU times: user 1h 3min 8s, sys: 55 s, total: 1h 4min 3s\n",
      "Wall time: 17min 33s\n"
     ]
    }
   ],
   "source": [
    "num_steps = 801\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1)) / predictions.shape[0])\n",
    "\n",
    "def run_relu_computation(nb_hidden):\n",
    "    print('')\n",
    "    graph, optimizer, loss, preds = create_relu_graph(nb_hidden)\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        # This is a one-time operation which ensures the parameters get initialized as\n",
    "        # we described in the graph: random weights for the matrix, zeros for the\n",
    "        # biases. \n",
    "        tf.initialize_all_variables().run()\n",
    "        print('Initialized for {0} hidden relu'.format(nb_hidden))\n",
    "        for step in range(num_steps):\n",
    "            # Run the computations. We tell .run() that we want to run the optimizer,\n",
    "            # and get the loss value and the training predictions returned as numpy\n",
    "            # arrays.\n",
    "            _, l, predictions = session.run([optimizer, loss, preds['train']])\n",
    "            if (step % 100 == 0):\n",
    "                print('Loss at step %d: %f' % (step, l))\n",
    "                print('Training accuracy: %.1f%%' % accuracy(\n",
    "                predictions, train_labels[:train_subset, :]))\n",
    "                # Calling .eval() on valid_prediction is basically like calling run(), but\n",
    "                # just to get that one numpy array. Note that it recomputes all its graph\n",
    "                # dependencies.\n",
    "                print('Validation accuracy: %.1f%%' % accuracy(\n",
    "                    preds['valid'].eval(), valid_labels))\n",
    "        print('Test accuracy: %.1f%%' % accuracy(\n",
    "            preds['test'].eval(), test_labels))\n",
    "    \n",
    "%time run_relu_computation(10)\n",
    "%time run_relu_computation(100)\n",
    "%time run_relu_computation(500)\n",
    "%time run_relu_computation(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression example **with** SGD: 1-hidden layer neural network with rectified linear units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "def create_sgd_relu_graph(nb_hidden):\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        # Input data. For the training data, we use a placeholder that will be fed\n",
    "        # at run time with a training minibatch.\n",
    "        tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, image_size * image_size))\n",
    "        tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "        tf_valid_dataset = tf.constant(valid_dataset)\n",
    "        tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "        # hidden layer\n",
    "        weights_1 = tf.Variable(tf.truncated_normal([image_size * image_size, nb_hidden]))\n",
    "        biases_1 = tf.Variable(tf.zeros([nb_hidden]))\n",
    "        hidden = tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1)\n",
    "        \n",
    "        # output layer\n",
    "        weights_2 = tf.Variable(tf.truncated_normal([nb_hidden, num_labels]))\n",
    "        biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "        logits = tf.matmul(hidden, weights_2) + biases_2\n",
    "\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  \n",
    "        # Optimizer.\n",
    "        # We are going to find the minimum of this loss using gradient descent.\n",
    "        optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "        # Predictions for the training, validation, and test data.\n",
    "        # These are not part of training, but merely here so that we can report\n",
    "        # accuracy figures as we train.\n",
    "        def compute_prediction(dataset):\n",
    "            return tf.nn.softmax(tf.matmul(tf.nn.relu(tf.matmul(dataset, weights_1) + biases_1), weights_2) + biases_2)\n",
    "        \n",
    "        train_prediction = tf.nn.softmax(logits)\n",
    "        valid_prediction = compute_prediction(tf_valid_dataset)\n",
    "        test_prediction = compute_prediction(tf_test_dataset)\n",
    "        \n",
    "    return (graph, optimizer, loss, \n",
    "            { 'dataset': tf_train_dataset, 'labels': tf_train_labels },\n",
    "            { 'train': train_prediction, 'valid': valid_prediction, 'test': test_prediction })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute accuracy for 10, 100, 500, 1000, 5000 and 10000 hidden nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initialized for 10 hidden relu\n",
      "Minibatch loss at step 0: 26.358131\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 14.4%\n",
      "Minibatch loss at step 500: 0.991928\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 64.9%\n",
      "Minibatch loss at step 1000: 0.861389\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 73.9%\n",
      "Minibatch loss at step 1500: 0.699962\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 76.7%\n",
      "Minibatch loss at step 2000: 0.684662\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 75.8%\n",
      "Minibatch loss at step 2500: 0.885164\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 75.4%\n",
      "Minibatch loss at step 3000: 0.757486\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 3500: 0.829638\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 77.9%\n",
      "Minibatch loss at step 4000: 0.738276\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 4500: 0.716405\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 5000: 0.566122\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 5500: 0.746961\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 6000: 0.719385\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.2%\n",
      "Test accuracy: 85.7%\n",
      "CPU times: user 18.3 s, sys: 2.11 s, total: 20.4 s\n",
      "Wall time: 10 s\n",
      "\n",
      "Initialized for 100 hidden relu\n",
      "Minibatch loss at step 0: 114.836761\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 24.5%\n",
      "Minibatch loss at step 500: 2.430319\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 71.9%\n",
      "Minibatch loss at step 1000: 1.189985\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 1500: 1.063856\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 76.5%\n",
      "Minibatch loss at step 2000: 0.755376\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 2500: 0.890840\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 3000: 0.842522\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 3500: 0.793056\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 4000: 0.841931\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 4500: 0.807904\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 5000: 0.769333\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 5500: 0.733205\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 6000: 0.987157\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 74.1%\n",
      "Test accuracy: 80.4%\n",
      "CPU times: user 54.8 s, sys: 2.58 s, total: 57.4 s\n",
      "Wall time: 20.2 s\n",
      "\n",
      "Initialized for 500 hidden relu\n",
      "Minibatch loss at step 0: 256.922913\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 31.1%\n",
      "Minibatch loss at step 500: 7.762336\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 1000: 5.513923\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.8%\n",
      "Minibatch loss at step 1500: 2.481597\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 2000: 1.391293\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 2500: 1.624496\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 3000: 1.395454\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 3500: 1.995783\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 4000: 1.665207\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 4500: 3.212435\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 5000: 1.721875\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 5500: 1.335876\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 6000: 0.968543\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.7%\n",
      "Test accuracy: 88.9%\n",
      "CPU times: user 3min 38s, sys: 9.53 s, total: 3min 48s\n",
      "Wall time: 1min 7s\n",
      "\n",
      "Initialized for 1000 hidden relu\n",
      "Minibatch loss at step 0: 325.523010\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 28.6%\n",
      "Minibatch loss at step 500: 12.975710\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 1000: 13.965302\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 1500: 7.048306\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2000: 2.586313\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 82.1%\n",
      "Minibatch loss at step 2500: 3.180361\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 3000: 2.083014\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 3500: 2.641422\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 4000: 4.432603\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 81.9%\n",
      "Minibatch loss at step 4500: 3.534695\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 79.3%\n",
      "Minibatch loss at step 5000: 3.125147\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 5500: 0.567632\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 82.1%\n",
      "Minibatch loss at step 6000: 1.590873\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 82.5%\n",
      "Test accuracy: 89.8%\n",
      "CPU times: user 6min 47s, sys: 12.3 s, total: 7min\n",
      "Wall time: 2min 6s\n",
      "\n",
      "Initialized for 5000 hidden relu\n",
      "Minibatch loss at step 0: 784.408875\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 30.0%\n",
      "Minibatch loss at step 500: 85.210892\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1000: 66.499298\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 83.5%\n",
      "Minibatch loss at step 1500: 34.615841\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 84.7%\n",
      "Minibatch loss at step 2000: 16.418045\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss at step 2500: 13.930907\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss at step 3000: 6.331506\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 85.0%\n",
      "Minibatch loss at step 3500: 18.748985\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 83.6%\n",
      "Minibatch loss at step 4000: 15.630989\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 4500: 21.551569\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 84.0%\n",
      "Minibatch loss at step 5000: 29.609280\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss at step 5500: 5.700211\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 85.2%\n",
      "Minibatch loss at step 6000: 4.388310\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 85.4%\n",
      "Test accuracy: 92.2%\n",
      "CPU times: user 33min 42s, sys: 59.2 s, total: 34min 41s\n",
      "Wall time: 9min 48s\n",
      "\n",
      "Initialized for 10000 hidden relu\n",
      "Minibatch loss at step 0: 1236.856934\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 28.8%\n",
      "Minibatch loss at step 500: 150.778091\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 1000: 156.318375\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 84.6%\n",
      "Minibatch loss at step 1500: 62.937904\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 84.7%\n",
      "Minibatch loss at step 2000: 14.102482\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 85.4%\n",
      "Minibatch loss at step 2500: 44.623924\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 85.1%\n",
      "Minibatch loss at step 3000: 7.309281\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 85.6%\n",
      "Minibatch loss at step 3500: 23.074881\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 85.1%\n",
      "Minibatch loss at step 4000: 29.036211\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 83.9%\n",
      "Minibatch loss at step 4500: 20.463251\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 5000: 49.936974\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 85.7%\n",
      "Minibatch loss at step 5500: 8.601078\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 6000: 17.064001\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.6%\n",
      "Test accuracy: 92.6%\n",
      "CPU times: user 1h 7min 12s, sys: 1min 45s, total: 1h 8min 57s\n",
      "Wall time: 19min 19s\n"
     ]
    }
   ],
   "source": [
    "num_steps = 6001\n",
    "\n",
    "def run_sgd_relu_computation(nb_hidden):\n",
    "    print('')\n",
    "    graph, optimizer, loss, feed, preds = create_sgd_relu_graph(nb_hidden)\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.initialize_all_variables().run()\n",
    "        print('Initialized for {0} hidden relu'.format(nb_hidden))\n",
    "        for step in range(num_steps):\n",
    "            # Pick an offset within the training data, which has been randomized.\n",
    "            # Note: we could use better randomization across epochs.\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            # Generate a minibatch.\n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "            # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "            # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "            # and the value is the numpy array to feed to it.\n",
    "            feed_dict = {feed['dataset'] : batch_data, feed['labels'] : batch_labels}\n",
    "            _, l, predictions = session.run(\n",
    "                [optimizer, loss, preds['train']], feed_dict=feed_dict)\n",
    "            if (step % 500 == 0):\n",
    "                print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "                print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "                print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "                    preds['valid'].eval(), valid_labels))\n",
    "        print(\"Test accuracy: %.1f%%\" % accuracy(preds['test'].eval(), test_labels))\n",
    "    \n",
    "%time run_sgd_relu_computation(10)\n",
    "%time run_sgd_relu_computation(100)\n",
    "%time run_sgd_relu_computation(500)\n",
    "%time run_sgd_relu_computation(1000)\n",
    "%time run_sgd_relu_computation(5000)\n",
    "%time run_sgd_relu_computation(10000)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "2_fullyconnected.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
